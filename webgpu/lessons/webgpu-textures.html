<!DOCTYPE html><!-- this file is auto-generated from webgpu/lessons/webgpu-textures.md. Do not edited directly --><!--
Copyright 2023, GfxFundamentals Contributors
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are
met:

* Redistributions of source code must retain the above copyright
  notice, this list of conditions and the following disclaimer.

* Redistributions in binary form must reproduce the above
  copyright notice, this list of conditions and the following disclaimer
  in the documentation and/or other materials provided with the
  distribution.

* Neither the name of GfxFundamentals nor the names of the
  contributors may be used to endorse or promote products derived from
  this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.


--><html lang="en"><head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="How to use Textures">
<meta name="keywords" content="webgpu graphics">
<meta name="thumbnail" content="https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-textures_en.jpg">

<meta property="og:title" content="WebGPU Textures">
<meta property="og:type" content="website">
<meta property="og:image" content="https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-textures_en.jpg">
<meta property="og:description" content="How to use Textures">
<meta property="og:url" content="https://webgpufundamentals.org/webgpu/lessons/webgpu-textures.html">

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@greggman">
<meta name="twitter:creator" content="@greggman">
<meta name="twitter:domain" content="webgpufundamentals.org">
<meta name="twitter:title" content="WebGPU Textures">
<meta name="twitter:url" content="https://webgpufundamentals.org/webgpu/lessons/webgpu-textures.html">
<meta name="twitter:description" content="How to use Textures">
<meta name="twitter:image:src" content="https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-textures_en.jpg">

<script type="application/ld+json">
{
  "@context":"https://schema.org",
  "@graph":[
    {
      "@type":"WebSite",
      "@id":"https://webgpufundamentals.org/#website",
      "url":"https://webgpufundamentals.org/",
      "name":"webgpufundamentals"
    },
    {
      "@type":"ImageObject",
      "@id":"https://webgpufundamentals.org/webgpu/lessons/webgpu-textures.html#primaryimage",
      "url":"https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-textures_en.jpg",
      "width":1200,
      "height":630
    },
    {
      "@type":"WebPage",
      "@id":"https://webgpufundamentals.org/webgpu/lessons/webgpu-textures.html#webpage",
      "url":"https://webgpufundamentals.org/webgpu/lessons/webgpu-textures.html",
      "inLanguage":"en",
      "name":"WebGPU Textures",
      "keywords":"webgpu graphics programming",
      "isPartOf":{
        "@id":"https://webgpufundamentals.org/#website"
      },
      "primaryImageOfPage":{
        "@id":"https://webgpufundamentals.org/webgpu/lessons/webgpu-textures.html#primaryimage"
      }
    }
  ]
}
</script>

<title>WebGPU Textures</title>
<link href="/webgpu/lessons/resources/webgpufundamentals-icon.png" rel="shortcut icon" type="image/png">
<link rel="apple-touch-icon" href="/webgpu/lessons/resources/webgpufundamentals-icon.png">
<link rel="icon" href="/webgpu/lessons/resources/webgpufundamentals-icon.png">
<link rel="stylesheet" href="/webgpu/lessons/resources/lesson.css">
</head>
<body>
<div class="webgpu_navbar">
  <div>
    <select class="language">
    <option value="/webgpu/lessons/webgpu-textures.html" selected="">English
</option></select>


    <a href="#toc">Table of Contents</a>
  </div>
</div>
<div class="webgpu_header">
  <h1><a href="/">webgpufundamentals.org</a></h1>
<style>
#forkongithub>div {
    background: #000;
    color: #fff;
    font-family: arial,sans-serif;
    text-align: center;
    font-weight: bold;
    padding: 5px 40px;
    font-size: 0.9rem;
    line-height: 1.3rem;
    position: relative;
    transition: 0.5s;
    display: block;
    width: 400px;
    position: absolute;
    top: 0;
    right: 0;
    transform: translateX(200px) rotate(45deg) translate(10px,70px);
    box-shadow: 4px 4px 10px rgba(0,0,0,0.8);
    pointer-events: auto;
}
#forkongithub a {
  text-decoration: none;
  color: #fff;
}
#forkongithub>div:hover {
    background: #c11;
    color: #fff;
}
#forkongithub .contributors {
  font-size: 0.75rem;
  background: rgba(255,255,255,0.2);
  line-height: 1.2;
  padding: 0.1em;
}
#forkongithub>div::before,#forkongithub>div::after {
    content: "";
    width: 100%;
    display: block;
    position: absolute;
    top: 1px;
    left: 0;
    height: 1px;
    background: #fff;
}
#forkongithub>div::after {
    bottom: 1px;
    top: auto;
}

#forkongithub{
    z-index: 9999;
    /* needed for firefox */
    overflow: hidden;
    width: 300px;
    height: 300px;
    position: absolute;
    right: 0;
    top: 0;
    pointer-events: none;
}
#forkongithub svg{
  width: 1em;
  height: 1em;
  vertical-align: middle;
}
#forkongithub img {
  width: 1em;
  height: 1em;
  border-radius: 100%;
  vertical-align: middle;
}

@media (max-width: 900px) {
    #forkongithub>div {
        line-height: 1.2rem;
    }
}
@media (max-width: 700px) {
  #forkongithub {
    display: none;
  }
}
@media (max-width: 410px) {
    #forkongithub>div {
        font-size: 0.7rem;
        transform: translateX(150px) rotate(45deg) translate(20px,40px);
    }
}

</style>
<div id="forkongithub"><div><div><a href="https://github.com/gfxfundamentals/webgpufundamentals">Fix, Fork, Contribute <!--?xml version="1.0" encoding="UTF-8" standalone="no"?-->

<svg width="100%" height="100%" viewBox="0 0 136 133" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" xmlns:serif="http://www.serif.com/" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:2;">
    <g transform="matrix(3.92891,0,0,3.92891,67.867,129.125)">
        <path d="M0,-31.904C-8.995,-31.904 -16.288,-24.611 -16.288,-15.614C-16.288,-8.417 -11.621,-2.312 -5.148,-0.157C-4.333,-0.008 -4.036,-0.511 -4.036,-0.943C-4.036,-1.329 -4.05,-2.354 -4.058,-3.713C-8.589,-2.729 -9.545,-5.897 -9.545,-5.897C-10.286,-7.779 -11.354,-8.28 -11.354,-8.28C-12.833,-9.29 -11.242,-9.27 -11.242,-9.27C-9.607,-9.155 -8.747,-7.591 -8.747,-7.591C-7.294,-5.102 -4.934,-5.821 -4.006,-6.238C-3.858,-7.29 -3.438,-8.008 -2.972,-8.415C-6.589,-8.826 -10.392,-10.224 -10.392,-16.466C-10.392,-18.244 -9.757,-19.698 -8.715,-20.837C-8.883,-21.249 -9.442,-22.905 -8.556,-25.148C-8.556,-25.148 -7.188,-25.586 -4.076,-23.478C-2.777,-23.84 -1.383,-24.02 0.002,-24.026C1.385,-24.02 2.779,-23.84 4.08,-23.478C7.19,-25.586 8.555,-25.148 8.555,-25.148C9.444,-22.905 8.885,-21.249 8.717,-20.837C9.761,-19.698 10.392,-18.244 10.392,-16.466C10.392,-10.208 6.583,-8.831 2.954,-8.428C3.539,-7.925 4.06,-6.931 4.06,-5.411C4.06,-3.234 4.04,-1.477 4.04,-0.943C4.04,-0.507 4.333,0 5.16,-0.159C11.628,-2.318 16.291,-8.419 16.291,-15.614C16.291,-24.611 8.997,-31.904 0,-31.904" style="fill:white;"></path>
    </g>
</svg>
</a></div></div></div>

</div>


<div class="container">
  <div class="lesson-title">
    <h1>WebGPU Textures</h1>
  </div>
  <div class="lesson">
    <div class="lesson-main">
      <p>In this article we’ll cover the fundamentals of textures. In previous articles
we covered the other major ways to pass data into a shader. They were
<a href="webgpu-inter-stage-variables.html">inter-stage variables</a>,
<a href="webgpu-uniforms.html">uniforms</a>, <a href="webgpu-storage-buffers.html">storage-buffers</a>,
and <a href="webgpu-vertex-buffers">vertex-buffers</a>. The last major way to pass data
into a shader is textures.</p>
<p>Textures most often represent a 2d image. A 2d image is just a 2d array of
color values so you might wonder, why do we need textures for 2d arrays?
We could just use storage buffers as 2d arrays. What makes textures special
is that they can be accessed by special hardware called a <em>sampler</em>. A
sampler can read up to 16 different values in a texture and blend them together
in a way that is useful for many common use cases.</p>
<p>As one example, lets say I want to draw a 2d image larger than its original size.</p>
<div class="center">
  <div>
    <div><img class="pixel-perfect" src="resources/kiana.png" style="max-width: 100%; width: 128px; height: 128px; image-rendering: pixelated; image-rendering: crisp-edges;"></div>
    <div style="text-align: center;">original</div>
  </div>
</div>
<p>If we just simply take a single pixel from the original image to make each pixel in the larger image
we’ll end up with the first example below. If instead, for a given pixel in the larger image we consider
multiple pixels from the original image we can get results like the 2nd image below.</p>
<div class="webgpu_center compare">
  <div>
    <div><img class="pixel-perfect" src="resources/kiana.png" style="max-width: 100%; width: 512px; height: 512px; image-rendering: pixelated; image-rendering: crisp-edges;"></div>
    <div>un-filtered</div>
  </div>
  <div>
    <div><img class="pixel-perfect" src="resources/kiana.png" style="max-width: 100%; width: 512px; height: 512px;"></div>
    <div>filtered</div>
  </div>
</div>
<p>While there are WGSL functions that will get an individual pixel from a texture and there are use cases
for that, those functions are not all that interesting because we could do the same with storage buffers.
The interesting WGSL functions for textures are ones that filter and can read multiple pixels.</p>
<p>These WGSL functions take a texture which represents that data, a sampler which represents how
we want to pull data out of the texture, and a texture coordinate which specifies where we want to
get a value from the texture.</p>
<p>Texture coordinates for 2D textures go from 0.0 to 1.0 across and down a texture regardless
of the actual size of the texture. <sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup></p>
<div class="webgpu_center"><img src="resources/texture-coordinates-diagram.svg" style="width: 500px;"></div>
<p>Let’s take one of our samples from <a href="webgpu-inter-stage-variables.html">the article on inter-stage variables</a>
and modify it to draw with a texture.</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">struct OurVertexShaderOutput {
  @builtin(position) position: vec4f,
-  @location(0) color: vec4f,
+  @location(0) texcoord: vec2f,
};

@vertex fn vs(
  @builtin(vertex_index) vertexIndex : u32
) -&gt; OurVertexShaderOutput {
-  var pos = array&lt;vec2f, 3&gt;(
-    vec2f( 0.0,  0.5),  // top center
-    vec2f(-0.5, -0.5),  // bottom left
-    vec2f( 0.5, -0.5)   // bottom right
-  );
-  var color = array&lt;vec4f, 3&gt;(
-    vec4f(1, 0, 0, 1), // red
-    vec4f(0, 1, 0, 1), // green
-    vec4f(0, 0, 1, 1), // blue
-  );
+  var pos = array&lt;vec2f, 6&gt;(
+    // 1st triangle
+    vec2f( 0.0,  0.0),  // center
+    vec2f( 1.0,  0.0),  // right, center
+    vec2f( 0.0,  1.0),  // center, top
+
+    // 2st triangle
+    vec2f( 0.0,  1.0),  // center, top
+    vec2f( 1.0,  0.0),  // right, center
+    vec2f( 1.0,  1.0),  // right, top
+  );

  var vsOutput: OurVertexShaderOutput;
-  vsOutput.position = vec4f(pos[vertexIndex], 0.0, 1.0);
-  vsOutput.color = color[vertexIndex];
+  let xy = pos[vertexIndex];
+  vsOutput.position = vec4f(xy, 0.0, 1.0);
+  vsOutput.texcoord = xy;
  return vsOutput;
}

+@group(0) @binding(0) var ourSampler: sampler;
+@group(0) @binding(1) var ourTexture: texture_2d&lt;f32&gt;;

@fragment fn fs(fsInput: OurVertexShaderOutput) -&gt; @location(0) vec4f {
-  return fsInput.color;
+  return textureSample(ourTexture, ourSampler, fsInput.texcoord);
}
</pre>
<p>Above we changed from 3 vertices that draw a centered triangle to 6 vertices
that draw a quad in the top right corner of the canvas.</p>
<p>We changed <code class="notranslate" translate="no">OutVertexShaderOutput</code> to pass <code class="notranslate" translate="no">texcoord</code>, a <code class="notranslate" translate="no">vec2f</code> so we can
pass texture coordinates to the fragment shader. We changed the vertex shader
to set <code class="notranslate" translate="no">vsOutput.texcoord</code> to the same as the clip space position we pulled
out of our hard coded array of positions. <code class="notranslate" translate="no">vsOutput.texcoord</code> will be
interpolated between the 3 vertices of each triangle when passed to the
fragment shader.</p>
<p>We then declared a sampler and texture and referenced those in our fragment
shader. The function <code class="notranslate" translate="no">textureSample</code> <em>samples</em> a texture. The first parameter
is the texture to sample. The 2nd parameter is the sampler to specify how
to sample the texture. The 3rd is the texture coordinate to sample.</p>
<p>Now we need to create a texture data. We’ll make a 5x7 texel <code class="notranslate" translate="no">F</code> <sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup></p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const kTextureWidth = 5;
  const kTextureHeight = 7;
  const _ = [255,   0,   0, 255];  // red
  const y = [255, 255,   0, 255];  // yellow
  const b = [  0,   0, 255, 255];  // blue
  const textureData = new Uint8Array([
    b, _, _, _, _,
    _, y, y, y, _,
    _, y, _, _, _,
    _, y, y, _, _,
    _, y, _, _, _,
    _, y, _, _, _,
    _, _, _, _, _,
  ].flat());
</pre>
<p>Hopefully you can see the <code class="notranslate" translate="no">F</code> in there as well as a blue texel in the top
left corner (the first value).</p>
<p>We’re going to create a <code class="notranslate" translate="no">rgba8unorm</code> texture. <code class="notranslate" translate="no">rgba8unorm</code> means the texture will
have red, green, blue, and alpha values. Each value will be 8 bits unsigned, and
will be normalized when used in the texture. <code class="notranslate" translate="no">unorm</code> means <code class="notranslate" translate="no">unsigned normalize</code>
which is fancy way of saying the value will be converted from (0 to 255) to (0 to 1).</p>
<p>In other words if the value we put in the texture is <code class="notranslate" translate="no">[64, 128, 192, 255]</code> the value
in the shader will end up being <code class="notranslate" translate="no">[64 / 255, 128 / 255, 192 / 255, 255 / 255]</code> or to
put it another way <code class="notranslate" translate="no">[0.25, 0.50, 0.75, 1.00]</code></p>
<p>Now that we have the data we need to make a texture</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const tex = device.createTexture({
    size: [kTextureWidth, kTextureHeight, 1],
    format: 'rgba8unorm',
    usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.COPY_DST,
  });
</pre>
<p>For <code class="notranslate" translate="no">device.createTexture</code>, the <code class="notranslate" translate="no">size</code> parameter should be pretty obvious. The
format is <code class="notranslate" translate="no">rgba8unorm</code> as mentioned above. For the <code class="notranslate" translate="no">usage</code>, <code class="notranslate" translate="no">TEXTURE_BINDING</code>
says we want to be able to bind this texture into a bind group and <code class="notranslate" translate="no">COPY_DST</code>
means we want to be able to copy data to it.</p>
<p>Next we need to do just that and copy our data to it.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  device.queue.writeTexture(
      { texture: tex },
      textureData,
      { bytesPerRow: kTextureWidth * 4 },
      { width: kTextureWidth, height: kTextureHeight },
  );
</pre>
<p>For <code class="notranslate" translate="no">device.queue.writeTexture</code> the first parameter is the texture we want to update.
The second is the data we want to copy do it. The 3rd defines how to read that data
when copying it to the texture. <code class="notranslate" translate="no">bytesPerRow</code> specifies how many bytes to get from
one row of the source data to the next row. Finally, the least parameter specifies
the size of the copy.</p>
<p>We also need to make a sampler</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const sampler = device.createSampler();
</pre>
<p>We need to add both the texture and the sampler to a bind group with bindings
that match the <code class="notranslate" translate="no">@binding(?)</code>s we put in the shader.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const bindGroup = device.createBindGroup({
    layout: pipeline.getBindGroupLayout(0),
    entries: [
      { binding: 0, resource: sampler },
      { binding: 1, resource: tex.createView() },
    ],
  });
</pre>
<p>To update our rendering we need to specify the bind group and render 6 vertices
to render our quad consisting of 2 triangles.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">    const pass = encoder.beginRenderPass(renderPassDescriptor);
    pass.setPipeline(pipeline);
+    pass.setBindGroup(0, bindGroup);
-    pass.draw(3);  // call our vertex shader 3 times
+    pass.draw(6);  // call our vertex shader 6 times
    pass.end();
</pre>
<p>and running it we get this</p>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-simple-textured-quad.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-simple-textured-quad.html" target="_blank">click here to open in a separate window</a>
</div>

<p></p>
<p><strong>Why is the F upside down?</strong></p>
<p>If you go back and reference the texture coordinate diagram again you can see
that texture coordinate 0,0 references the first texel of the texture. The
position in the center of the canvas of our quad is 0,0 and we use that value as
a texture coordinate so it’s doing what the diagram shows, a 0,0 texture
coordinate is referencing the first blue texel.</p>
<p>To fix this there are 2 common solutions.</p>
<ol>
<li>
<p>Flip the texture coordinates</p>
<p>In this example we could change the texture coordinate in either
the vertex shader</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">-  vsOutput.texcoord = xy;
+  vsOutput.texcoord = vec2f(xy.x, 1.0 - xy.y);
</pre>
<p>or fragment shader</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">-  return textureSample(ourTexture, ourSampler, fsInput.texcoord);
+  let texcoord = vec2f(fsInput.texcoord.x, 1.0 - fsInput.texcoord.y);
+  return textureSample(ourTexture, ourSampler, texcoord);
</pre>
<p>Of course if we were supplying texture coordinates via <a href="webgpu-vertex-buffers.html">vertex buffers</a>
or <a href="webgpu-storage-buffers.html">storage buffers</a> then ideally we’d flip them
at the source.</p>
</li>
<li>
<p>Flip the texture data</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no"> const textureData = new Uint8Array([
-   b, _, _, _, _,
-   _, y, y, y, _,
-   _, y, _, _, _,
-   _, y, y, _, _,
-   _, y, _, _, _,
-   _, y, _, _, _,
-   _, _, _, _, _,
+   _, _, _, _, _,
+   _, y, _, _, _,
+   _, y, _, _, _,
+   _, y, y, _, _,
+   _, y, _, _, _,
+   _, y, y, y, _,
+   b, _, _, _, _,
 ].flat());
</pre>
<p>Once we’ve flipped the data what used to be at the top is now at the bottom
and now the bottom of the left pixel of the original image is the first data
in the texture and now at what texture coordinate 0,0 refers to. This is why
often texture coordinates are considered to go from 0 at the bottom to 1 at
the top.</p>
<div class="webgpu_center"><img src="resources/texture-coordinates-y-flipped.svg" style="width: 500px;"></div>
<p>Flipping the data is common enough that there are even options when loading
textures from images, videos, and canvases to flip the data for you.</p>
</li>
</ol>
<h2 id="magfilter">magFilter</h2>
<p>In the example above we use a sampler with its default settings. Since we are
drawing the 5x7 texture larger than it’s original 5x7 texels the sampler uses
what’s called the <code class="notranslate" translate="no">magFilter</code> or, the filter used when magnifying the texture.
If we change it from <code class="notranslate" translate="no">nearest</code> to to <code class="notranslate" translate="no">linear</code> then it will linearly interpolate
between 4 pixels.</p>
<div class="webgpu-center center diagram"><div data-diagram="linear-interpolation" style="display: inline-block; width: 600px;"></div></div>
<p>Texture coordinates are often called “UVs” (pronounced you-vees) so, in the
diagram above, <code class="notranslate" translate="no">uv</code> is the texture coordinate. For a given uv, the closest 4
pixels are chosen. <code class="notranslate" translate="no">t1</code> is the horizontal distance between the top left chosen
pixel’s center and the pixel to its right’s center where 0 means we are
horizontally at the left pixel’s center and 1 means we are horizontally at the
right chosen pixel’s center. <code class="notranslate" translate="no">t2</code> is similar but vertically.</p>
<p><code class="notranslate" translate="no">t1</code> is the used to <em>“mix”</em> between the top 2 pixels to produce an intermediate
color. <em>mix</em> linear interpolates between 2 values so when <code class="notranslate" translate="no">t1</code> is 0 we get only
the first color. When <code class="notranslate" translate="no">t1</code> = 1 we get only the second color. Values between 0
and 1 produce proportional mix. For example 0.3 would be would be 70% of the
first color and 30% of second color. Similarly, a second intermediate color is
computed for the bottom 2 pixels. Finally, <code class="notranslate" translate="no">t2</code> is used to mix the two
intermediate colors into a final color.</p>
<p>Another thing to notice, at the bottom of the diagram are 2 settings more
sampler settings, <code class="notranslate" translate="no">addressModeU</code> and <code class="notranslate" translate="no">addressModeV</code>. We can set these to
<code class="notranslate" translate="no">repeat</code> or <code class="notranslate" translate="no">clamp-to-edge</code>. When set to ‘repeat’, when our texture coordinate
is within half a texel of the edge of the texture we wrap around and blend with
pixels on the opposite side of the texture. When set to ‘clamp-to-edge’, for the
purposes of calculating which color to return, the texture coordinate is clamped
so that it can’t go into the last half texel on each edge. This has the effect
of showing the edge colors for any texture coordinate that outside that range.</p>
<p>Let’s update the sample so we can draw the quad with all of these options.</p>
<p>First let’s create a sampler for each combination of settings.
We’ll also create a bind group that uses that sampler.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">+  const bindGroups = [];
+  for (let i = 0; i &lt; 8; ++i) {
-   const sampler = device.createSampler();
+   const sampler = device.createSampler({
+      addressModeU: (i &amp; 1) ? 'repeat' : 'clamp-to-edge',
+      addressModeV: (i &amp; 2) ? 'repeat' : 'clamp-to-edge',
+      magFilter: (i &amp; 4) ? 'linear' : 'nearest',
+    });

    const bindGroup = device.createBindGroup({
      layout: pipeline.getBindGroupLayout(0),
      entries: [
        { binding: 0, resource: sampler },
        { binding: 1, resource: tex.createView() },
      ],
    });
+    bindGroups.push(bindGroup);
+  }
</pre>
<p>We’ll make some settings</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const settings = {
    addressModeU: 'repeat',
    addressModeV: 'repeat',
    magFilter: 'linear',
  };
</pre>
<p>and at render time we’ll look at the settings to decide which
bind group to use.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  function render() {
+    const ndx = (settings.addressModeU === 'repeat' ? 1 : 0) +
+                (settings.addressModeV === 'repeat' ? 2 : 0) +
+                (settings.magFilter === 'linear' ? 4 : 0);
+    const bindGroup = bindGroups[ndx];
   ...
</pre>
<p>Now all we need to do is provide some UI to let us change the settings
and when the setting change we need to re-render. I’m using a library
called “muigui” which at the moment has a API similar to <a href="https://github.com/dataarts/dat.gui">dat.GUI</a></p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">import GUI from '/3rdparty/muigui-0.x.module.js';

...

  const settings = {
    addressModeU: 'repeat',
    addressModeV: 'repeat',
    magFilter: 'linear',
  };

  const addressOptions = ['repeat', 'clamp-to-edge'];
  const filterOptions = ['nearest', 'linear'];

  const gui = new GUI();
  Object.assign(gui.domElement.style, {right: '', left: '15px'});
  gui.add(settings, 'addressModeU', addressOptions).onChange(render);
  gui.add(settings, 'addressModeV', addressOptions).onChange(render);
  gui.add(settings, 'magFilter', filterOptions).onChange(render);
</pre>
<p>The code above declares <code class="notranslate" translate="no">settings</code> and then creates a ui to set them
and calls <code class="notranslate" translate="no">render</code> when they change.</p>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-simple-textured-quad-linear.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-simple-textured-quad-linear.html" target="_blank">click here to open in a separate window</a>
</div>

<p></p>
<p>Since our fragment shader is receiving interpolated texture coordinates, as our shader
calls <code class="notranslate" translate="no">textureSample</code> with those coordinates, it gets different blended colors as it’s
asked to provide a color for each pixel being rendered.
Notice how with the address modes set to ‘repeat’ we can see WebGPU is “sampling”
from the texels on the opposite side of the texture.</p>
<h2 id="minfilter">minFilter</h2>
<p>There is also a setting for <code class="notranslate" translate="no">minFilter</code> which does similar math to <code class="notranslate" translate="no">magFilter</code>
for when the texture is drawn smaller than it’s size. When set to ‘linear’
it also chooses 4 pixels and blends them following similar math to that above.</p>
<p>The problem is, choosing 4 blended pixels from larger
texture to render say 1 pixel, the color will change an we’ll get flickering.</p>
<p>Let’s do it so we can see the issue</p>
<p>First let’s make our canvas low-res. To do this we need to update our
css so the browser doesn’t do the same <code class="notranslate" translate="no">magFilter: 'linear'</code> effect on
our canvas. We can do this by setting the css as follows</p>
<pre class="prettyprint showlinemods notranslate lang-css" translate="no">canvas {
  display: block;  /* make the canvas act like a block   */
  width: 100%;     /* make the canvas fill its container */
  height: 100%;
+  image-rendering: pixelated;
+  image-rendering: crisp-edges;
}
</pre>
<p>Next let’s lower the resolution of the canvas in our <code class="notranslate" translate="no">ResizeObserver</code> callback</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const observer = new ResizeObserver(entries =&gt; {
    for (const entry of entries) {
      const canvas = entry.target;
-      const width = entry.contentBoxSize[0].inlineSize / 64 | 0;
-      const height = entry.contentBoxSize[0].blockSize / 64 | 0;
+      const width = entry.contentBoxSize[0].inlineSize / 64 | 0;
+      const height = entry.contentBoxSize[0].blockSize / 64 | 0;
      canvas.width = Math.min(width, device.limits.maxTextureDimension2D);
      canvas.height = Math.min(height, device.limits.maxTextureDimension2D);
      // re-render
      render();
    }
  });
  observer.observe(canvas);
</pre>
<p>We’re going to move and scale the quad so we’ll add in a uniform buffer just
like we did in the first example in <a href="webgpu-uniforms.html">the article on uniforms</a>.</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">struct OurVertexShaderOutput {
  @builtin(position) position: vec4f,
  @location(0) texcoord: vec2f,
};

+struct Uniforms {
+  scale: vec2f,
+  offset: vec2f,
+};
+
+@group(0) @binding(2) var&lt;uniform&gt; uni: Uniforms;

@vertex fn vs(
  @builtin(vertex_index) vertexIndex : u32
) -&gt; OurVertexShaderOutput {
  var pos = array&lt;vec2f, 6&gt;(
    // 1st triangle
    vec2f( 0.0,  0.0),  // center
    vec2f( 1.0,  0.0),  // right, center
    vec2f( 0.0,  1.0),  // center, top

    // 2st triangle
    vec2f( 0.0,  1.0),  // center, top
    vec2f( 1.0,  0.0),  // right, center
    vec2f( 1.0,  1.0),  // right, top
  );

  var vsOutput: OurVertexShaderOutput;
  let xy = pos[vertexIndex];
-  vsOutput.position = vec4f(xy, 0.0, 1.0);
+  vsOutput.position = vec4f(xy * uni.scale + uni.offset, 0.0, 1.0);
  vsOutput.texcoord = xy;
  return vsOutput;
}

@group(0) @binding(0) var ourSampler: sampler;
@group(0) @binding(1) var ourTexture: texture_2d&lt;f32&gt;;

@fragment fn fs(fsInput: OurVertexShaderOutput) -&gt; @location(0) vec4f {
  return textureSample(ourTexture, ourSampler, fsInput.texcoord);
}
</pre>
<p>So now we need to create a uniform buffer</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">+  // create a buffer for the uniform values
+  const uniformBufferSize =
+    2 * 4 + // scale is 2 32bit floats (4bytes each)
+    2 * 4;  // offset is 2 32bit floats (4bytes each)
+  const uniformBuffer = device.createBuffer({
+    label: 'uniforms for quad',
+    size: uniformBufferSize,
+    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
+  });
+
+  // create a typedarray to hold the values for the uniforms in JavaScript
+  const uniformValues = new Float32Array(uniformBufferSize / 4);
+
+  // offsets to the various uniform values in float32 indices
+  const kScaleOffset = 0;
+  const kOffsetOffset = 2;

  const bindGroups = [];
  for (let i = 0; i &lt; 8; ++i) {
    const sampler = device.createSampler({
      addressModeU: (i &amp; 1) ? 'repeat' : 'clamp-to-edge',
      addressModeV: (i &amp; 2) ? 'repeat' : 'clamp-to-edge',
      magFilter: (i &amp; 4) ? 'linear' : 'nearest',
    });

    const bindGroup = device.createBindGroup({
      layout: pipeline.getBindGroupLayout(0),
      entries: [
        { binding: 0, resource: sampler },
        { binding: 1, resource: tex.createView() },
+        { binding: 2, resource: { buffer: uniformBuffer }},
      ],
    });
    bindGroups.push(bindGroup);
  }
</pre>
<p>And we need code to set the uniform’s values and upload them to the GPU.
We’re going to animate this so we’ll also change the render to use
<code class="notranslate" translate="no">requestAnimationFrame</code>.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  function render(time) {
    time *= 0.001;
    const ndx = (settings.addressModeU === 'repeat' ? 1 : 0) +
                (settings.addressModeV === 'repeat' ? 2 : 0) +
                (settings.magFilter === 'linear' ? 4 : 0);
    const bindGroup = bindGroups[ndx];

+    // compute a scale that will draw our 0 to 1 clip space quad
+    // 2x2 pixels in the canvas.
+    const scaleX = 4 / canvas.width;
+    const scaleY = 4 / canvas.height;
+
+    uniformValues.set([scaleX, scaleY], kScaleOffset); // set the scale
+    uniformValues.set([Math.sin(time * 0.25) * 0.9, 0.5], kOffsetOffset); // set the scale
+
+    // copy the values from JavaScript to the GPU
+    device.queue.writeBuffer(uniformBuffer, 0, uniformValues);

    ...

+    requestAnimationFrame(render);
  }
+  requestAnimationFrame(render);

  const observer = new ResizeObserver(entries =&gt; {
    for (const entry of entries) {
      const canvas = entry.target;
      const width = entry.contentBoxSize[0].inlineSize / 64 | 0;
      const height = entry.contentBoxSize[0].blockSize / 64 | 0;
      canvas.width = Math.min(width, device.limits.maxTextureDimension2D);
      canvas.height = Math.min(height, device.limits.maxTextureDimension2D);
-      // re-render
-      render();
    }
  });
  observer.observe(canvas);
}
</pre>
<p>The code above sets the scale so that we’ll draw the quad 2x2 pixels in the canvas.
It also sets the offset from -0.9 to +0.9 using <code class="notranslate" translate="no">Math.sin</code> so that the quad will
slowly go back and forth across the canvas.</p>
<p>Finally let’s add <code class="notranslate" translate="no">minFilter</code> to our settings and combinations</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const bindGroups = [];
  for (let i = 0; i &lt; 16; ++i) {
    const sampler = device.createSampler({
      addressModeU: (i &amp; 1) ? 'repeat' : 'clamp-to-edge',
      addressModeV: (i &amp; 2) ? 'repeat' : 'clamp-to-edge',
      magFilter: (i &amp; 4) ? 'linear' : 'nearest',
+      minFilter: (i &amp; 8) ? 'linear' : 'nearest',
    });

...

  const settings = {
    addressModeU: 'repeat',
    addressModeV: 'repeat',
    magFilter: 'linear',
+    minFilter: 'linear',
  };

  const addressOptions = ['repeat', 'clamp-to-edge'];
  const filterOptions = ['nearest', 'linear'];

  const gui = new GUI();
  Object.assign(gui.domElement.style, {right: '', left: '15px'});
  -gui.add(settings, 'addressModeU', addressOptions).onChange(render);
  -gui.add(settings, 'addressModeV', addressOptions).onChange(render);
  -gui.add(settings, 'magFilter', filterOptions).onChange(render);
+  gui.add(settings, 'addressModeU', addressOptions);
+  gui.add(settings, 'addressModeV', addressOptions);
+  gui.add(settings, 'magFilter', filterOptions);
+  gui.add(settings, 'minFilter', filterOptions);

  function render(time) {
    time *= 0.001;
    const ndx = (settings.addressModeU === 'repeat' ? 1 : 0) +
                (settings.addressModeV === 'repeat' ? 2 : 0) +
-                (settings.magFilter === 'linear' ? 4 : 0);
+                (settings.magFilter === 'linear' ? 4 : 0) +
+                (settings.minFilter === 'linear' ? 8 : 0);
</pre>
<p>We no longer need to call <code class="notranslate" translate="no">render</code> when a setting changes since we’re
rendering constantly using <code class="notranslate" translate="no">requestAnimationFrame</code> (often called “rAF”
and this loop is often called a “rAF loop”)</p>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-simple-textured-quad-minfilter.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-simple-textured-quad-minfilter.html" target="_blank">click here to open in a separate window</a>
</div>

<p></p>
<p>You can see the quad is flickering and changing colors. If the <code class="notranslate" translate="no">minFilter</code>
is set to <code class="notranslate" translate="no">nearest</code> then for each of the 2x2 pixels of the quad it’s picking
one pixel from our texture. If you set it to <code class="notranslate" translate="no">linear</code> then it does the
bilinear filtering we mentioned above but it still flickers.</p>
<p>One reason is, the quad is draw with real numbers but pixels are integers.
The texture coordinates are interpolated from the real numbers, or rather, they
are computed from the real numbers.</p>
<div class="webgpu-center center diagram"><div data-diagram="pixel-to-texcoords" style="display: inline-block; width: 600px;"></div></div>
<p>In the diagram above, the <span style="color: red;">red</span> rectangle above
represents the quad we are asked the GPU to draw, based on the values we return
from our vertex shader. When the GPU draws, it computes which pixels’ centers
are inside our quad (well, our 2 triangles). Then, it computes what interpolated
inter-stage variable value to pass to the fragment shader, based on where the
center of the pixel to be drawn is, relative to the where the original points
are. In our fragment shader we then pass that texture coordinate to the WGSL
<code class="notranslate" translate="no">textureSample</code> function and get back a sampled color as the previous diagram
showed. Hopefully you can see why the colors are flickering. You can see them
blend to different colors depending on which UV coordinates are computed for the
pixel being drawn.</p>
<p>Textures offer a solution to this problem. It’s called mip-mapping. I think (but could be wrong)
that “mipmap” stands for “multi-image-pyramid-map”.</p>
<p>What we take our texture and create a smaller texture that is half the size in each dimension,
rounding down. We then fill the smaller texture with blended colors from the first original texture.
We keep doing this until we get to a 1x1 texture. In our example we have a 5x7 texel texture.
Dividing by 2 in each dimension and rounding down gives us a 2x3 texel texture. We take that one
and repeat so we end up with 1x1 texel texture.</p>
<div class="webgpu-center center diagram"><div data-diagram="mips" style="display: inline-block;"></div></div>
<p>Given a mipmap, we can then ask the GPU to choose a smaller mip level when smaller than the original size.</p>
<p>The best algorithm for blending the pixels from one mip to the next is
a topic of research as well as a matter of opinion. As a first idea, here’s some code that
generates each mip from the previous mip by bilinear filtering (like we did above).</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">const lerp = (a, b, t) =&gt; a + (b - a) * t;
const mix = (a, b, t) =&gt; a.map((v, i) =&gt; lerp(v, b[i], t));
const bilinearFilter = (tl, tr, bl, br, t1, t2) =&gt; {
  const t = mix(tl, tr, t1);
  const b = mix(bl, br, t1);
  return mix(t, b, t2);
};

const createNextMipLevelRgba8Unorm = ({data: src, width: srcWidth, height: srcHeight}) =&gt; {
  // compute the size of the next mip
  const dstWidth = Math.max(1, srcWidth / 2 | 0);
  const dstHeight = Math.max(1, srcHeight / 2 | 0);
  const dst = new Uint8Array(dstWidth * dstHeight * 4);

  const getSrcPixel = (x, y) =&gt; {
    const offset = (y * srcWidth + x) * 4;
    return src.subarray(offset, offset + 4);
  };

  for (let y = 0; y &lt; dstHeight; ++y) {
    for (let x = 0; x &lt; dstWidth; ++x) {
      // compute texcoord of the center of the destination texel
      const u = (x + 0.5) / dstWidth;
      const v = (y + 0.5) / dstHeight;

      // compute the same texcoord in the source - 0.5 a pixel
      const au = (u * srcWidth - 0.5);
      const av = (v * srcHeight - 0.5);

      // compute the src top left texel coord (not texcoord)
      const tx = au | 0;
      const ty = av | 0;

      // compute the mix amounts between pixels
      const t1 = au % 1;
      const t2 = av % 1;

      // get the 4 pixels
      const tl = getSrcPixel(tx, ty);
      const tr = getSrcPixel(tx + 1, ty);
      const bl = getSrcPixel(tx, ty);
      const br = getSrcPixel(tx + 1, ty + 1);

      // copy the "sampled" result into the dest.
      const dstOffset = (y * dstWidth + x) * 4;
      dst.set(bilinearFilter(tl, tr, bl, br, t1, t2), dstOffset);
    }
  }
  return { data: dst, width: dstWidth, height: dstHeight };
};

const generateMips = (src, srcWidth) =&gt; {
  const srcHeight = src.length / 4 / srcWidth;

  // populate with first mip level (base level)
  let mip = { data: src, width: srcWidth, height: srcHeight, };
  const mips = [mip];

  while (mip.width &gt; 1 || mip.height &gt; 1) {
    mip = createNextMipLevelRgba8Unorm(mip);
    mips.push(mip);
  }
  return mips;
};
</pre>
<p>We’ll go over how to do this on the GPU in <a href="webgpu-generate-mips.html">another article</a>.
For now, we can use the code above to generate a mipmap</p>
<p>We pass our texture data to the function above, and it returns an array of mip level data.
We can then create a texture with all the mip levels</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const mips = generateMips(textureData, kTextureWidth);

  const tex = device.createTexture({
    label: 'yellow F on red',
+    size: [mips[0].width, mips[0].height, 1],
+    mipLevelCount: mips.length,
    format: 'rgba8unorm',
    usage:
      GPUTextureUsage.TEXTURE_BINDING |
      GPUTextureUsage.COPY_DST,
  });
  mips.forEach(({data, width, height}, mipLevel) =&gt; {
    device.queue.writeTexture(
-      { texture: tex },
-      textureData,
-      { bytesPerRow: kTextureWidth * 4 },
-      { width: kTextureWidth, height: kTextureHeight },
+      { texture: tex, mipLevel },
+      data,
+      { bytesPerRow: width * 4 },
+      { width, height },
    );
  });
</pre>
<p>Notice we pass in <code class="notranslate" translate="no">mipLevelCount</code> to the number of mip levels. WebGPU will then create
the correct sized mip level at each level. We then copy the data to each level by specifying
the <code class="notranslate" translate="no">mipLevel</code></p>
<p>And with that the GPU is choose the smallest mip to draw and are flickering is gone.</p>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-simple-textured-quad-mipmap.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-simple-textured-quad-mipmap.html" target="_blank">click here to open in a separate window</a>
</div>

<p></p>
<p>But wait, there’s MORE</p>
<p>Just like we have a <code class="notranslate" translate="no">magFilter</code> and a <code class="notranslate" translate="no">minFilter</code> both of which which can be <code class="notranslate" translate="no">nearest</code> or <code class="notranslate" translate="no">linear</code>,
there is also a <code class="notranslate" translate="no">mipmapFilter</code> setting which can also be <code class="notranslate" translate="no">nearest</code> or <code class="notranslate" translate="no">linear</code>.</p>
<p>This chooses if we blend between mip levels. In <code class="notranslate" translate="no">mipmapFilter: 'linear'</code>, colors are sampled
from 2 mip levels, either with nearest or linear filtering based on the previous settings,
then, those 2 colors are again <code class="notranslate" translate="no">mix</code>ed in a similar way.</p>
<p>This comes up most when drawing things in 3D. How to draw in 3D is covered in <a href="webgpu-perspective.html">other articles</a>. For now, we’ll just hard code a quad with data that happens to
represent a plane that goes off into the distance.</p>
<div class="webgpu-center center diagram"><div data-diagram="blended-mips" style="display: inline-block;"></div></div>
<div class="webgpu-center center diagram"><div data-diagram="checkered-mips" style="display: inline-block;"></div></div>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-simple-textured-quad-mipmapfilter.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-simple-textured-quad-mipmapfilter.html" target="_blank">click here to open in a separate window</a>
</div>

<p></p>
<p>TODO: loading
TODO: texture formats
TODO: 3D, 2D Array, Cube maps</p>
<!-- keep this at the bottom of the article -->
<script type="module" src="/3rdparty/pixel-perfect.js"></script>
<script type="module" src="webgpu-textures.js"></script>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>Whether texture coordinates go up (0 = bottom, 1 = top) or down (0 = top, 1 = bottom) is
a matter of perspective. What’s important is that texture coordinate 0,0 references the first data in
the texture. <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p>A texel is a “texture element” vs a pixel which is a “picture element”.
For me texel and pixel are basically synonymous but some people prefer to use
the world <em>texel</em> when discussing textures. <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>

    </div>
    <div class="lesson-sidebar">
        <select class="language">
    <option value="/webgpu/lessons/webgpu-textures.html" selected="">English
</option></select>


        <div id="toc">
          <ul>  <li>Basics</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-fundamentals.html">Fundamentals</a></li>
<li><a href="/webgpu/lessons/webgpu-inter-stage-variables.html">Inter-stage Variables</a></li>
<li><a href="/webgpu/lessons/webgpu-uniforms.html">Uniforms</a></li>
<li><a href="/webgpu/lessons/webgpu-storage-buffers.html">Storage Buffers</a></li>
<li><a href="/webgpu/lessons/webgpu-vertex-buffers.html">Vertex Buffers</a></li>
<li><a href="/webgpu/lessons/webgpu-textures.html">Textures</a></li>
<li><a href="/webgpu/lessons/webgpu-constants.html">Constants</a></li>
<li><a href="/webgpu/lessons/webgpu-memory-layout.html">Data Memory Layout</a></li>
<li><a href="/webgpu/lessons/webgpu-wgsl.html">WGSL</a></li>
<li><a href="/webgpu/lessons/webgpu-how-it-works.html">How It Works</a></li>
        </ul>
  <li>Mics</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-from-webgl.html">WebGPU from WebGL</a></li>
<li><a href="/webgpu/lessons/webgpu-resources.html">Resources / References</a></li>
        </ul></ul>
<ul>
  <li><a href="https://github.com/gfxfundamentals/webgpufundamentals">github</a></li>
  <li><a href="https://gpuweb.github.io/types/">WebGPU API Reference</a></li>
  <li><a href="https://www.w3.org/TR/webgpu/">WebGPU Spec</a></li>
  <li><a href="https://www.w3.org/TR/WGSL/">WGSL Spec</a></li>
</ul>

        </div>
    </div>
    <div class="lesson-comments">
        
    <div>Questions? <a href="http://stackoverflow.com/questions/tagged/webgpu">Ask on stackoverflow</a>.</div>
    <div>
       <a href="https://github.com/gfxfundamentals/webgpufundamentals/issues/new?assignees=&amp;labels=suggested+topic&amp;template=suggest-topic.md&amp;title=%5BSUGGESTION%5D">Suggestion</a>?
       <a href="https://github.com/gfxfundamentals/webgpufundamentals/issues/new?assignees=&amp;labels=&amp;template=request.md&amp;title=">Request</a>?
       <a href="https://github.com/gfxfundamentals/webgpufundamentals/issues/new?assignees=&amp;labels=bug+%2F+issue&amp;template=bug-issue-report.md&amp;title=">Issue</a>?
       <a href="https://github.com/gfxfundamentals/webgpufundamentals/issues/new?assignees=&amp;labels=bug+%2F+issue&amp;template=bug-issue-report.md&amp;title=">Bug</a>?
    </div>
    <div class="lesson-comment-notes">
       Use <b>&lt;pre&gt;&lt;code&gt;</b>code goes here<b>&lt;/code&gt;&lt;/pre&gt;</b> for code blocks
    </div>
  

        <div id="disqus_thread"></div>
        <script>
            var disqus_config = function () {
              this.page.url = `${window.location.origin}${window.location.pathname}`;
              this.page.identifier = `WebGPU Textures`;
            };
            (function() { // DON'T EDIT BELOW THIS LINE
                if (window.location.hostname.indexOf("webgpufundamentals.org") < 0) {
                    return;
                }
                var d = document, s = d.createElement('script');
                s.src = 'https://webgpufundamentals-org.disqus.com/embed.js';
                s.setAttribute('data-timestamp', +new Date());
                (d.head || d.body).appendChild(s);
            })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
        <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </div>
  </div>
</div>

<script>
const settings = {
  contribTemplate: "Thank you <a href=\"${html_url}\"><img src=\"${avatar_url}\"> ${login}</a><br>for <a href=\"https://github.com/${owner}/${repo}/commits?author=${login}\">${contributions} contributions</a>",
  owner: "gfxfundamentals",
  repo: "webgpufundamentals",
};
</script>
<script src="/contributors.js"></script>
<script src="/3rdparty/jquery-3.3.1.slim.min.js"></script>
<script src="/webgpu/lessons/resources/prettify.js"></script>
<script src="/webgpu/lessons/resources/lesson.js"></script>
<script>
(function() {
  if (window.location.hostname.indexOf("webgpufundamentals.org") < 0) {
      return;
  }

  function addScript(src, fn) {
    const script = document.createElement('script');
    const firstScript = document.getElementsByTagName('script')[0];
    script.async = true;
    script.defer = true;
    if (fn) {
      script.addEventListener('load', fn);
    }
    script.src = src;
    firstScript.parentNode.insertBefore(script, firstScript);
  }
  /*
  addScript('https://www.googletagmanager.com/gtag/js?id=UA-120733518-1', () => {
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-120733518-1');
  });
  */
}());
</script>






</body></html>