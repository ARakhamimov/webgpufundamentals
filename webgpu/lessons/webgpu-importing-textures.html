<!DOCTYPE html><!-- this file is auto-generated from webgpu/lessons/webgpu-importing-textures.md. Do not edited directly --><!--
Copyright 2023, GfxFundamentals Contributors
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are
met:

* Redistributions of source code must retain the above copyright
  notice, this list of conditions and the following disclaimer.

* Redistributions in binary form must reproduce the above
  copyright notice, this list of conditions and the following disclaimer
  in the documentation and/or other materials provided with the
  distribution.

* Neither the name of GfxFundamentals nor the names of the
  contributors may be used to endorse or promote products derived from
  this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.


--><html lang="en"><head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="How to load an Image into a texture">
<meta name="keywords" content="webgpu graphics">
<meta name="thumbnail" content="https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-importing-textures_en.jpg">

<meta property="og:title" content="WebGPU Importing Images into Textures">
<meta property="og:type" content="website">
<meta property="og:image" content="https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-importing-textures_en.jpg">
<meta property="og:description" content="How to load an Image into a texture">
<meta property="og:url" content="https://webgpufundamentals.org/webgpu/lessons/webgpu-importing-textures.html">

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@greggman">
<meta name="twitter:creator" content="@greggman">
<meta name="twitter:domain" content="webgpufundamentals.org">
<meta name="twitter:title" content="WebGPU Importing Images into Textures">
<meta name="twitter:url" content="https://webgpufundamentals.org/webgpu/lessons/webgpu-importing-textures.html">
<meta name="twitter:description" content="How to load an Image into a texture">
<meta name="twitter:image:src" content="https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-importing-textures_en.jpg">

<script type="application/ld+json">
{
  "@context":"https://schema.org",
  "@graph":[
    {
      "@type":"WebSite",
      "@id":"https://webgpufundamentals.org/#website",
      "url":"https://webgpufundamentals.org/",
      "name":"webgpufundamentals"
    },
    {
      "@type":"ImageObject",
      "@id":"https://webgpufundamentals.org/webgpu/lessons/webgpu-importing-textures.html#primaryimage",
      "url":"https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-importing-textures_en.jpg",
      "width":1200,
      "height":630
    },
    {
      "@type":"WebPage",
      "@id":"https://webgpufundamentals.org/webgpu/lessons/webgpu-importing-textures.html#webpage",
      "url":"https://webgpufundamentals.org/webgpu/lessons/webgpu-importing-textures.html",
      "inLanguage":"en",
      "name":"WebGPU Importing Images into Textures",
      "keywords":"webgpu graphics programming",
      "isPartOf":{
        "@id":"https://webgpufundamentals.org/#website"
      },
      "primaryImageOfPage":{
        "@id":"https://webgpufundamentals.org/webgpu/lessons/webgpu-importing-textures.html#primaryimage"
      }
    }
  ]
}
</script>

<title>WebGPU Importing Images into Textures</title>
<link href="/webgpu/lessons/resources/webgpufundamentals-icon.png" rel="shortcut icon" type="image/png">
<link rel="apple-touch-icon" href="/webgpu/lessons/resources/webgpufundamentals-icon.png">
<link rel="icon" href="/webgpu/lessons/resources/webgpufundamentals-icon.png">
<link rel="stylesheet" href="/webgpu/lessons/resources/lesson.css">
</head>
<body>
<div class="webgpu_navbar">
  <div>
    <select class="language">
    <option value="/webgpu/lessons/webgpu-importing-textures.html" selected="">English
</option></select>


    <a href="#toc">Table of Contents</a>
  </div>
</div>
<div class="webgpu_header">
  <h1><a href="/">webgpufundamentals.org</a></h1>
<style>
#forkongithub>div {
    background: #000;
    color: #fff;
    font-family: arial,sans-serif;
    text-align: center;
    font-weight: bold;
    padding: 5px 40px;
    font-size: 0.9rem;
    line-height: 1.3rem;
    position: relative;
    transition: 0.5s;
    display: block;
    width: 400px;
    position: absolute;
    top: 0;
    right: 0;
    transform: translateX(160px) rotate(45deg) translate(10px,70px);
    box-shadow: 4px 4px 10px rgba(0,0,0,0.8);
    pointer-events: auto;
}
#forkongithub a {
  text-decoration: none;
  color: #fff;
}
#forkongithub>div:hover {
    background: #c11;
    color: #fff;
}
#forkongithub .contributors {
  font-size: 0.75rem;
  background: rgba(255,255,255,0.2);
  line-height: 1.2;
  padding: 0.1em;
}
#forkongithub>div::before,#forkongithub>div::after {
    content: "";
    width: 100%;
    display: block;
    position: absolute;
    top: 1px;
    left: 0;
    height: 1px;
    background: #fff;
}
#forkongithub>div::after {
    bottom: 1px;
    top: auto;
}

#forkongithub{
    z-index: 9999;
    /* needed for firefox */
    overflow: hidden;
    width: 300px;
    height: 300px;
    position: absolute;
    right: 0;
    top: 0;
    pointer-events: none;
}
#forkongithub svg{
  width: 1em;
  height: 1em;
  vertical-align: middle;
}
#forkongithub img {
  width: 1em;
  height: 1em;
  border-radius: 100%;
  vertical-align: middle;
}

@media (max-width: 900px) {
    #forkongithub>div {
        line-height: 1.2rem;
    }
}
@media (max-width: 700px) {
  #forkongithub {
    display: none;
  }
}
@media (max-width: 410px) {
    #forkongithub>div {
        font-size: 0.7rem;
        transform: translateX(150px) rotate(45deg) translate(20px,40px);
    }
}

</style>
<div id="forkongithub"><div><div><a href="https://github.com/gfxfundamentals/webgpufundamentals">Fix, Fork, Contribute <!--?xml version="1.0" encoding="UTF-8" standalone="no"?-->

<svg width="100%" height="100%" viewBox="0 0 136 133" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" xmlns:serif="http://www.serif.com/" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:2;">
    <g transform="matrix(3.92891,0,0,3.92891,67.867,129.125)">
        <path d="M0,-31.904C-8.995,-31.904 -16.288,-24.611 -16.288,-15.614C-16.288,-8.417 -11.621,-2.312 -5.148,-0.157C-4.333,-0.008 -4.036,-0.511 -4.036,-0.943C-4.036,-1.329 -4.05,-2.354 -4.058,-3.713C-8.589,-2.729 -9.545,-5.897 -9.545,-5.897C-10.286,-7.779 -11.354,-8.28 -11.354,-8.28C-12.833,-9.29 -11.242,-9.27 -11.242,-9.27C-9.607,-9.155 -8.747,-7.591 -8.747,-7.591C-7.294,-5.102 -4.934,-5.821 -4.006,-6.238C-3.858,-7.29 -3.438,-8.008 -2.972,-8.415C-6.589,-8.826 -10.392,-10.224 -10.392,-16.466C-10.392,-18.244 -9.757,-19.698 -8.715,-20.837C-8.883,-21.249 -9.442,-22.905 -8.556,-25.148C-8.556,-25.148 -7.188,-25.586 -4.076,-23.478C-2.777,-23.84 -1.383,-24.02 0.002,-24.026C1.385,-24.02 2.779,-23.84 4.08,-23.478C7.19,-25.586 8.555,-25.148 8.555,-25.148C9.444,-22.905 8.885,-21.249 8.717,-20.837C9.761,-19.698 10.392,-18.244 10.392,-16.466C10.392,-10.208 6.583,-8.831 2.954,-8.428C3.539,-7.925 4.06,-6.931 4.06,-5.411C4.06,-3.234 4.04,-1.477 4.04,-0.943C4.04,-0.507 4.333,0 5.16,-0.159C11.628,-2.318 16.291,-8.419 16.291,-15.614C16.291,-24.611 8.997,-31.904 0,-31.904" style="fill:white;"></path>
    </g>
</svg>
</a></div></div></div>

</div>


<div class="container">
  <div class="lesson-title">
    <h1>WebGPU Importing Images into Textures</h1>
  </div>
  <div class="lesson">
    <div class="lesson-main">
      <p>We covered some basics about using textures <a href="webgpu-textures.html">in the previous article</a>.
In this article we’ll cover importing a texture from an image.</p>
<p>In the previous article we’d created a texture by calling <code class="notranslate" translate="no">device.createTexture</code> and then
put data in the texture by calling <code class="notranslate" translate="no">device.queue.writeTexture</code>. There’s another function
on <code class="notranslate" translate="no">device.queue</code> called <code class="notranslate" translate="no">device.queue.copyExternalImageToTexture</code> that let’s us copy
an image into a texture.</p>
<p>It can take an <a href="https://developer.mozilla.org/en-US/docs/Web/API/ImageBitmap"><code class="notranslate" translate="no">ImageBitmap</code></a> so let’s take <a href="webgpu-textures.html#magFilter">the magFilter example from the previous article</a> and change it to import a few images.</p>
<p>First we need some code to get an <a href="https://developer.mozilla.org/en-US/docs/Web/API/ImageBitmap"><code class="notranslate" translate="no">ImageBitmap</code></a> from an image</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  async function loadImageBitmap(url) {
    const res = await fetch(url);
    const blob = await res.blob();
    return await createImageBitmap(blob, { colorSpaceConversion: 'none' });
  }
</pre>
<p>The code above calls <code class="notranslate" translate="no">fetch</code> with the url of an image. This returns a <code class="notranslate" translate="no">Response</code>. We then
use that to load a <code class="notranslate" translate="no">Blob</code> which opaquely represents the data of the image file. We then pass
that to <a href="https://developer.mozilla.org/en-US/docs/Web/API/createImageBitmap"><code class="notranslate" translate="no">createImageBitmap</code></a> which is a standard browser function to create an <a href="https://developer.mozilla.org/en-US/docs/Web/API/ImageBitmap"><code class="notranslate" translate="no">ImageBitmap</code></a>.
We pass <code class="notranslate" translate="no">{ colorSpaceConversion: 'none' }</code> to tell the browser not to apply any color space. It’s up to you if
you want the browser to apply a color space or not. Often in WebGPU we might load
an image that is a normal map or a height map or something that is not color data.
In those cases we definitely don’t want the browser to muck with the data in the image.</p>
<p>Now that we have code to create an <a href="https://developer.mozilla.org/en-US/docs/Web/API/ImageBitmap"><code class="notranslate" translate="no">ImageBitmap</code></a> let’s load one and create a texture of the same size.</p>
<p>We’ll load this image</p>
<div class="webgpu_center"><img src="../resources/images/f-texture.png"></div>
<p>I was taught once that a texture with an <code class="notranslate" translate="no">F</code> in it is a good example texture because we can instantly
see its orientation.</p>
<div class="webgpu_center"><img src="resources/images/f-orientation.svg"></div>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">-  const texture = device.createTexture({
-    label: 'yellow F on red',
-    size: [kTextureWidth, kTextureHeight],
-    format: 'rgba8unorm',
-    usage:
-      GPUTextureUsage.TEXTURE_BINDING |
-      GPUTextureUsage.COPY_DST,
-  });
+  const url = 'resources/images/f-texture.png';
+  const source = await loadImageBitmap(url);
+  const texture = device.createTexture({
+    label: url,
+    format: 'rgba8unorm',
+    size: [source.width, source.height],
+    usage: GPUTextureUsage.TEXTURE_BINDING |
+           GPUTextureUsage.COPY_DST |
+           GPUTextureUsage.RENDER_ATTACHMENT,
+  });
</pre>
<p>Note that <code class="notranslate" translate="no">copyExternalImageToTexture</code> requires that we include to
<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/GPUTextureUsage.COPY_DST"><code class="notranslate" translate="no">GPUTextureUsage.COPY_DST</code></a> and <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/GPUTextureUsage.RENDER_ATTACHMENT"><code class="notranslate" translate="no">GPUTextureUsage.RENDER_ATTACHMENT</code></a>
usage flags.</p>
<p>So then we can copy the <a href="https://developer.mozilla.org/en-US/docs/Web/API/ImageBitmap"><code class="notranslate" translate="no">ImageBitmap</code></a> to the texture</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">-  device.queue.writeTexture(
-      { texture },
-      textureData,
-      { bytesPerRow: kTextureWidth * 4 },
-      { width: kTextureWidth, height: kTextureHeight },
-  );
+  device.queue.copyExternalImageToTexture(
+    { source, flipY: true },
+    { texture },
+    { width: source.width, height: source.height },
+  );
</pre>
<p>The parameters to <code class="notranslate" translate="no">copyExternalImageToTexture</code> are
The source, the destination, the size. For the source
we can specify <code class="notranslate" translate="no">flipY: true</code> if we want the texture flipped on load.</p>
<p>And that works!</p>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-simple-textured-quad-import-no-mips.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-simple-textured-quad-import-no-mips.html" target="_blank">click here to open in a separate window</a>
</div>

<p></p>
<h2 id="generating-mips-on-the-gpu">Generating mips on the GPU</h2>
<p>In <a href="webgpu-textures.html#mipmapFilter">the previous article we also generated a mipmap</a>
but in that case we had easy access to the image data. When importing an image, we
could draw that image into a 2D canvas, the call <code class="notranslate" translate="no">getImageData</code> to get the data, and
finally generate mips and upload. That would be pretty slow. It would also potentially
be lossy since how canvas 2D renders is intentionally implementation dependant.</p>
<p>When we generated mip levels we did a bilinear interpolation which is exactly what
the GPU does with <code class="notranslate" translate="no">minFilter: linear</code>. We can use that feature to generate mip levels
on the GPU</p>
<p>Let’s modify the <a href="webgpu-textures.html#mipmapFilter">minmapFilter example from the previous article</a>
to load images and generate mips using the GPU</p>
<p>First, let’s change the code that creates the texture to create mip levels. We need to know how many
to create which we can calculate like this</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const numMipLevels = (...sizes) =&gt; {
    const maxSize = Math.max(...sizes);
    return 1 + Math.log2(maxSize) | 0;
  };
</pre>
<p>We can call that with 1 or more numbers and it will return the number of mips needed, so for example
<code class="notranslate" translate="no">numMipLevels(123, 456)</code> returns <code class="notranslate" translate="no">9</code>.</p>
<blockquote>
<ul>
<li>level 0: 123, 456</li>
<li>level 1: 61, 228</li>
<li>level 2: 30, 114</li>
<li>level 3: 15, 57</li>
<li>level 4: 7, 28</li>
<li>level 5: 3, 14</li>
<li>level 6: 1, 7</li>
<li>level 7: 1, 3</li>
<li>level 8: 1, 1</li>
</ul>
<p>9 mip levels</p>
</blockquote>
<p><code class="notranslate" translate="no">Math.log2</code> tells us the power of 2 we need to make our number.
In other words, <code class="notranslate" translate="no">Math.log2(8) = 3</code> because 2<sup>3</sup> = 8. Another way to say the same thing is, <code class="notranslate" translate="no">Math.log2</code> tells us how
many times can we divide this number by 2.</p>
<blockquote>
<pre class="prettyprint showlinemods notranslate notranslate" translate="no">Math.log2(8)
          8 / 2 = 4
                  4 / 2 = 2
                          2 / 2 = 1`
</pre>
</blockquote>
<p>So we can divide 8 by 2 three times. That’s exactly what we need to compute how many mip levels to make.
It’s <code class="notranslate" translate="no">Math.log2(largestSize) + 1</code>. 1 for the original size mip level 0</p>
<p>So, we can now create the right number of mip levels</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const texture = device.createTexture({
    label: url,
    format: 'rgba8unorm',
    mipLevelCount: numMipLevels(source.width, source.height),
    size: [source.width, source.height],
    usage: GPUTextureUsage.TEXTURE_BINDING |
           GPUTextureUsage.COPY_DST |
           GPUTextureUsage.RENDER_ATTACHMENT,
  });
  device.queue.copyExternalImageToTexture(
    { source, flipY: true, },
    { texture },
    { width: source.width, height: source.height },
  );
</pre>
<p>To generate the next mip level, we’ll draw a textured quad, just like we’ve been doing, from the
existing mip level, to the next level, with <code class="notranslate" translate="no">minFilter: linear</code>.</p>
<p>Here’s the code</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const generateMips = (() =&gt; {
    let pipeline;
    let sampler;

    return function generateMips(device, texture) {
      if (!pipeline) {
        const module = device.createShaderModule({
          label: 'textured quad shaders for mip level generation',
          code: `
            struct VSOutput {
              @builtin(position) position: vec4f,
              @location(0) texcoord: vec2f,
            };

            @vertex fn vs(
              @builtin(vertex_index) vertexIndex : u32
            ) -&gt; VSOutput {
              var pos = array&lt;vec2f, 6&gt;(

                vec2f( 0.0,  0.0),  // center
                vec2f( 1.0,  0.0),  // right, center
                vec2f( 0.0,  1.0),  // center, top

                // 2st triangle
                vec2f( 0.0,  1.0),  // center, top
                vec2f( 1.0,  0.0),  // right, center
                vec2f( 1.0,  1.0),  // right, top
              );

              var vsOutput: VSOutput;
              let xy = pos[vertexIndex];
              vsOutput.position = vec4f(xy * 2.0 - 1.0, 0.0, 1.0);
              vsOutput.texcoord = vec2f(xy.x, 1.0 - xy.y);
              return vsOutput;
            }

            @group(0) @binding(0) var ourSampler: sampler;
            @group(0) @binding(1) var ourTexture: texture_2d&lt;f32&gt;;

            @fragment fn fs(fsInput: VSOutput) -&gt; @location(0) vec4f {
              return textureSample(ourTexture, ourSampler, fsInput.texcoord);
            }
          `,
        });
        pipeline = device.createRenderPipeline({
          label: 'mip level generator pipeline',
          layout: 'auto',
          vertex: {
            module,
            entryPoint: 'vs',
          },
          fragment: {
            module,
            entryPoint: 'fs',
            targets: [{ format: texture.format }],
          },
        });

        sampler = device.createSampler({
          minFilter: 'linear',
        });
      }

      const encoder = device.createCommandEncoder({
        label: 'mip gen encoder',
      });

      let width = texture.width;
      let height = texture.height;
      let baseMipLevel = 0;
      while (width &gt; 1 || height &gt; 1) {
        width = Math.max(1, width / 2 | 0);
        height = Math.max(1, height / 2 | 0);

        const bindGroup = device.createBindGroup({
          layout: pipeline.getBindGroupLayout(0),
          entries: [
            { binding: 0, resource: sampler },
            { binding: 1, resource: texture.createView({baseMipLevel, mipLevelCount: 1}) },
          ],
        });

        ++baseMipLevel;

        const renderPassDescriptor = {
          label: 'our basic canvas renderPass',
          colorAttachments: [
            {
              view: texture.createView({baseMipLevel, mipLevelCount: 1}),
              clearValue: [0.3, 0.3, 0.3, 1],
              loadOp: 'clear',
              storeOp: 'store',
            },
          ],
        };

        const pass = encoder.beginRenderPass(renderPassDescriptor);
        pass.setPipeline(pipeline);
        pass.setBindGroup(0, bindGroup);
        pass.draw(6);  // call our vertex shader 6 times
        pass.end();
      }

      const commandBuffer = encoder.finish();
      device.queue.submit([commandBuffer]);
    };
  })();
</pre>
<p>The code above looks long but it’s almost the exact same code we’ve been using in our examples with textures so far.
What’s changed</p>
<ul>
<li>
<p>We make a closure to hold on to 3 variables. <code class="notranslate" translate="no">module</code>, <code class="notranslate" translate="no">sampler</code>, <code class="notranslate" translate="no">pipelineByFormat</code>.
For <code class="notranslate" translate="no">module</code> and <code class="notranslate" translate="no">sampler</code> we check if they have not be set and if not, we create a <code class="notranslate" translate="no">GPUSShaderModule</code>
and <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/GPUSampler"><code class="notranslate" translate="no">GPUSampler</code></a> which we can hold on to and use in the future.</p>
</li>
<li>
<p>We have a pair of shaders that are almost exactly the same as all the examples. The only difference
is this part</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">-  vsOutput.position = uni.matrix * vec4f(xy, 0.0, 1.0);
-  vsOutput.texcoord = xy * vec2f(1, 50);
+  vsOutput.position = vec4f(xy * 2.0 - 1.0, 0.0, 1.0);
+  vsOutput.texcoord = vec2f(xy.x, 1.0 - xy.y);
</pre>
<p>The hard coded quad position data we have in shader goes from 0.0 to 1.0 and so, as is, would only
cover the top right quarter texture we’re drawing to, just as it does in the examples. We need it to cover the entire
area so by multiplying by 2 and subtracting 1 we get a quad that goes from -1,-1 to +1,1.</p>
<p>We also flip the Y texture coordinate. This is because when drawing to the texture +1, +1 is at the top right
but we want the top right of the texture we are sampling to be there. The top right of the sampled texture is +1, 0</p>
</li>
<li>
<p>We have an object, <code class="notranslate" translate="no">pipelineByFormat</code> which we use as a map of pipelines to texture formats.
This is because a pipeline needs to know the format to use.</p>
</li>
<li>
<p>We check if we already have a pipeline for a particular format and if not create one</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">    if (!pipelineByFormat[texture.format]) {
      pipelineByFormat[texture.format] = device.createRenderPipeline({
        label: 'mip level generator pipeline',
        layout: 'auto',
        vertex: {
          module,
          entryPoint: 'vs',
        },
        fragment: {
          module,
          entryPoint: 'fs',
+          targets: [{ format: texture.format }],
        },
      });
    }
    const pipeline = pipelineByFormat[texture.format];
</pre>
<p>The only major difference here is <code class="notranslate" translate="no">targets</code> is set from the texture’s format,
not from the <code class="notranslate" translate="no">presentationFormat</code> we use when rendering to the canvas</p>
</li>
<li>
<p>We finally use some parameters to <code class="notranslate" translate="no">texture.createView</code></p>
<p>We loop over each mip level. We create a bind group for the last mip with data in it
and we set the renderPassDescriptor to draw to the next mip level. Then we encode
a renderPass for that specific mip level. When we’re done. All the mips will have
been filled out.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">    let width = texture.width;
    let height = texture.height;
    let baseMipLevel = 0;
    while (width &gt; 1 || height &gt; 1) {
      width = Math.max(1, width / 2 | 0);
      height = Math.max(1, height / 2 | 0);

      const bindGroup = device.createBindGroup({
        layout: pipeline.getBindGroupLayout(0),
        entries: [
          { binding: 0, resource: sampler },
+          { binding: 1, resource: texture.createView({baseMipLevel, mipLevelCount: 1}) },
        ],
      });

+      ++baseMipLevel;

      const renderPassDescriptor = {
        label: 'our basic canvas renderPass',
        colorAttachments: [
          {
+            view: texture.createView({baseMipLevel, mipLevelCount: 1}),
            loadOp: 'clear',
            storeOp: 'store',
          },
        ],
      };

      const pass = encoder.beginRenderPass(renderPassDescriptor);
      pass.setPipeline(pipeline);
      pass.setBindGroup(0, bindGroup);
      pass.draw(6);  // call our vertex shader 6 times
      pass.end();
    }

    const commandBuffer = encoder.finish();
    device.queue.submit([commandBuffer]);
</pre>
</li>
</ul>
<p>Let’s create some support functions make it simple load an image
into a texture and generate mips</p>
<p>Here’s a function that updates the first mip level and optionally flips the image.
If the image has mip levels then we generate them.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  function copySourceToTexture(device, texture, source, {flipY} = {}) {
    device.queue.copyExternalImageToTexture(
      { source, flipY, },
      { texture },
      { width: source.width, height: source.height },
    );

    if (texture.mipLevelCount &gt; 1) {
      generateMips(device, texture);
    }
  }
</pre>
<p>Here’s a function that given a source (in this case an <a href="https://developer.mozilla.org/en-US/docs/Web/API/ImageBitmap"><code class="notranslate" translate="no">ImageBitmap</code></a>) will
create a texture of the matching size and then call the previous function
to fill it in with the data</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  function createTextureFromSource(device, source, options = {}) {
    const texture = device.createTexture({
      format: 'rgba8unorm',
*      mipLevelCount: options.mips ? numMipLevels(source.width, source.height) : 1,
      size: [source.width, source.height],
      usage: GPUTextureUsage.TEXTURE_BINDING |
             GPUTextureUsage.COPY_DST |
             GPUTextureUsage.RENDER_ATTACHMENT,
    });
    copySourceToTexture(device, texture, source, options);
    return texture;
  }
</pre>
<p>and here’s a function that given a url will load the url as an <a href="https://developer.mozilla.org/en-US/docs/Web/API/ImageBitmap"><code class="notranslate" translate="no">ImageBitmap</code></a> call
call the previous function to create a texture and fill it with the contents of the image.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  async function createTextureFromImage(device, url, options) {
    const imgBitmap = await loadImageBitmap(url);
    return createTextureFromSource(device, imgBitmap, options);
  }
</pre>
<p>With those setup, the only major change to the <a href="webgpu-textures.html#mipmapFilter">mipmapFilter sample</a>
is this</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">-  const textures = [
-    createTextureWithMips(createBlendedMipmap(), 'blended'),
-    createTextureWithMips(createCheckedMipmap(), 'checker'),
-  ];
+  const textures = await Promise.all([
+    await createTextureFromImage(device, 'resources/images/f-texture.png', {mips: true, flipY: false}),
+    await createTextureFromImage(device, 'resources/images/coins.jpg', {mips: true}),
+    await createTextureFromImage(device, 'resources/images/Granite_paving_tileable_512x512.jpeg', {mips: true}),
+  ]);
</pre>
<p>The code above loads the F texture from above as well as these 2 textures</p>
<div class="webgpu_center"><img src="../resources/images/coins.jpg"> <img src="../resources/images/Granite_paving_tileable_512x512.jpeg"></div>
<p>And here it is</p>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-simple-textured-quad-import.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-simple-textured-quad-import.html" target="_blank">click here to open in a separate window</a>
</div>

<p></p>
<p>TBD: Atlas</p>
<p>TBD: Canvas</p>
<p>TBD: Video</p>

    </div>
    <div class="lesson-sidebar">
        <select class="language">
    <option value="/webgpu/lessons/webgpu-importing-textures.html" selected="">English
</option></select>


        <div id="toc">
          <ul>  <li>Basics</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-fundamentals.html">Fundamentals</a></li>
<li><a href="/webgpu/lessons/webgpu-inter-stage-variables.html">Inter-stage Variables</a></li>
<li><a href="/webgpu/lessons/webgpu-uniforms.html">Uniforms</a></li>
<li><a href="/webgpu/lessons/webgpu-storage-buffers.html">Storage Buffers</a></li>
<li><a href="/webgpu/lessons/webgpu-vertex-buffers.html">Vertex Buffers</a></li>
<li><a href="/webgpu/lessons/webgpu-textures.html">Textures</a></li>
<li><a href="/webgpu/lessons/webgpu-importing-textures.html">Importing Images</a></li>
<li><a href="/webgpu/lessons/webgpu-constants.html">Constants</a></li>
<li><a href="/webgpu/lessons/webgpu-memory-layout.html">Data Memory Layout</a></li>
<li><a href="/webgpu/lessons/webgpu-wgsl.html">WGSL</a></li>
<li><a href="/webgpu/lessons/webgpu-how-it-works.html">How It Works</a></li>
        </ul>
  <li>Misc</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-from-webgl.html">WebGPU from WebGL</a></li>
<li><a href="/webgpu/lessons/webgpu-resources.html">Resources / References</a></li>
<li><a href="/webgpu/lessons/webgpu-wgsl-function-reference.html">WGSL Function Reference</a></li>
        </ul></ul>
<ul>
  <li><a href="https://github.com/gfxfundamentals/webgpufundamentals">github</a></li>
  <!--<li><a href="https://google.github.io/tour-of-wgsl/">Tour of WGSL</a></li>-->
  <li><a href="https://gpuweb.github.io/types/">WebGPU API Reference</a></li>
  <li><a href="https://www.w3.org/TR/webgpu/">WebGPU Spec</a></li>
  <li><a href="https://www.w3.org/TR/WGSL/">WGSL Spec</a></li>
</ul>

        </div>
    </div>
    <div class="lesson-comments">
        
    <div>Questions? <a href="http://stackoverflow.com/questions/tagged/webgpu">Ask on stackoverflow</a>.</div>
    <div>
       <a href="https://github.com/gfxfundamentals/webgpufundamentals/issues/new?assignees=&amp;labels=suggested+topic&amp;template=suggest-topic.md&amp;title=%5BSUGGESTION%5D">Suggestion</a>?
       <a href="https://github.com/gfxfundamentals/webgpufundamentals/issues/new?assignees=&amp;labels=&amp;template=request.md&amp;title=">Request</a>?
       <a href="https://github.com/gfxfundamentals/webgpufundamentals/issues/new?assignees=&amp;labels=bug+%2F+issue&amp;template=bug-issue-report.md&amp;title=">Issue</a>?
       <a href="https://github.com/gfxfundamentals/webgpufundamentals/issues/new?assignees=&amp;labels=bug+%2F+issue&amp;template=bug-issue-report.md&amp;title=">Bug</a>?
    </div>
    <div class="lesson-comment-notes">
       Use <b>&lt;pre&gt;&lt;code&gt;</b>code goes here<b>&lt;/code&gt;&lt;/pre&gt;</b> for code blocks
    </div>
  

        <div id="disqus_thread"></div>
        <script>
            var disqus_config = function () {
              this.page.url = `${window.location.origin}${window.location.pathname}`;
              this.page.identifier = `WebGPU Importing Images into Textures`;
            };
            (function() { // DON'T EDIT BELOW THIS LINE
                if (window.location.hostname.indexOf("webgpufundamentals.org") < 0) {
                    return;
                }
                var d = document, s = d.createElement('script');
                s.src = 'https://webgpufundamentals-org.disqus.com/embed.js';
                s.setAttribute('data-timestamp', +new Date());
                (d.head || d.body).appendChild(s);
            })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
        <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </div>
  </div>
</div>

<script>
const settings = {
  contribTemplate: "Thank you <a href=\"${html_url}\"><img src=\"${avatar_url}\"> ${login}</a><br>for <a href=\"https://github.com/${owner}/${repo}/commits?author=${login}\">${contributions} contributions</a>",
  owner: "gfxfundamentals",
  repo: "webgpufundamentals",
};
</script>
<script src="/contributors.js"></script>
<script src="/3rdparty/jquery-3.3.1.slim.min.js"></script>
<script src="/webgpu/lessons/resources/prettify.js"></script>
<script src="/webgpu/lessons/resources/lesson.js"></script>
<script>
(function() {
  if (window.location.hostname.indexOf("webgpufundamentals.org") < 0) {
      return;
  }

  function addScript(src, fn) {
    const script = document.createElement('script');
    const firstScript = document.getElementsByTagName('script')[0];
    script.async = true;
    script.defer = true;
    if (fn) {
      script.addEventListener('load', fn);
    }
    script.src = src;
    firstScript.parentNode.insertBefore(script, firstScript);
  }
  /*
  addScript('https://www.googletagmanager.com/gtag/js?id=UA-120733518-1', () => {
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-120733518-1');
  });
  */
}());
</script>






</body></html>