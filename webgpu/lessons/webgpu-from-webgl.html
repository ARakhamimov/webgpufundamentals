<!DOCTYPE html>
<!-- this file is auto-generated from webgpu/lessons/webgpu-from-webgl.md. Do not edited directly -->
<!--
Copyright 2021, Gregg Tavares
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are
met:

*   Redistributions of source code must retain the above copyright
    notice, this list of conditions and the following disclaimer.

*   Redistributions in binary form must reproduce the above
    copyright notice, this list of conditions and the following disclaimer
    in the documentation and/or other materials provided with the
    distribution.

*   Neither the name of Gregg Tavares nor the names of the
    contributors may be used to endorse or promote products derived from
    this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-->
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="Comparing using WebGL to WebGPU" />
<meta name="keywords" content="webgpu graphics" />
<meta name="thumbnail" content="https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-from-webgl_en.jpg" />

<meta property="og:title" content="WebGPU from WebGL" />
<meta property="og:type" content="website" />
<meta property="og:image" content="https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-from-webgl_en.jpg" />
<meta property="og:description" content="Comparing using WebGL to WebGPU" />
<meta property="og:url" content="https://webgpufundamentals.org/webgpu/lessons/webgpu-from-webgl.html" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:site" content="@greggman" />
<meta name="twitter:creator" content="@greggman" />
<meta name="twitter:domain" content="webgpufundamentals.org" />
<meta name="twitter:title" content="WebGPU from WebGL" />
<meta name="twitter:url" content="https://webgpufundamentals.org/webgpu/lessons/webgpu-from-webgl.html" />
<meta name="twitter:description" content="Comparing using WebGL to WebGPU" />
<meta name="twitter:image:src" content="https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-from-webgl_en.jpg" />

<script type="application/ld+json">
{
  "@context":"https://schema.org",
  "@graph":[
    {
      "@type":"WebSite",
      "@id":"https://webgpufundamentals.org/#website",
      "url":"https://webgpufundamentals.org/",
      "name":"webgpufundamentals"
    },
    {
      "@type":"ImageObject",
      "@id":"https://webgpufundamentals.org/webgpu/lessons/webgpu-from-webgl.html#primaryimage",
      "url":"https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-from-webgl_en.jpg",
      "width":1200,
      "height":630
    },
    {
      "@type":"WebPage",
      "@id":"https://webgpufundamentals.org/webgpu/lessons/webgpu-from-webgl.html#webpage",
      "url":"https://webgpufundamentals.org/webgpu/lessons/webgpu-from-webgl.html",
      "inLanguage":"en",
      "name":"WebGPU from WebGL",
      "keywords":"webgpu graphics programming",
      "isPartOf":{
        "@id":"https://webgpufundamentals.org/#website"
      },
      "primaryImageOfPage":{
        "@id":"https://webgpufundamentals.org/webgpu/lessons/webgpu-from-webgl.html#primaryimage"
      }
    }
  ]
}
</script>

<title>WebGPU from WebGL</title>
<link href="/webgpu/lessons/resources/webgpufundamentals-icon.png" rel="shortcut icon" type="image/png">
<link rel="apple-touch-icon" href="/webgpu/lessons/resources/webgpufundamentals-icon.png">
<link rel="icon" href="/webgpu/lessons/resources/webgpufundamentals-icon.png">
<link rel="stylesheet" href="/webgpu/lessons/resources/lesson.css" />
</head>
<body>
<div class="webgpu_navbar">
  <div>
    <select class="language">
    <option value="/webgpu/lessons/webgpu-from-webgl.html" selected>English</a>
</select>


    <a href="#toc">Table of Contents</a>
  </div>
</div>
<div class="webgpu_header">
  <h1><a href="/">webgpufundamentals.org</a></h1>
<style>
#forkongithub a {
    background: #000;
    color: #fff;
    text-decoration: none;
    font-family: arial,sans-serif;
    text-align: center;
    font-weight: bold;
    padding: 5px 40px;
    font-size: 0.9rem;
    line-height: 2rem;
    position: relative;
    transition: 0.5s;
    display: block;
    width: 300px;
    position: absolute;
    top: 0;
    right: 0;
    transform: translateX(150px) rotate(45deg) translate(10px,70px);
    box-shadow: 4px 4px 10px rgba(0,0,0,0.8);
    pointer-events: auto;
}
#forkongithub a:hover {
    background: #c11;
    color: #fff;
}
#forkongithub a::before,#forkongithub a::after {
    content: "";
    width: 100%;
    display: block;
    position: absolute;
    top: 1px;
    left: 0;
    height: 1px;
    background: #fff;
}
#forkongithub a::after {
    bottom: 1px;
    top: auto;
}

#forkongithub{
    z-index: 9999;
    /* needed for firefox */
    overflow: hidden;
    width: 300px;
    height: 300px;
    position: absolute;
    right: 0;
    top: 0;
    pointer-events: none;
}
#forkongithub svg{
  width: 1em;
  height: 1em;
  vertical-align: middle;
}
@media (max-width: 900px) {
    #forkongithub a{
        line-height: 1.2rem;
    }
}
@media (max-width: 700px) {
  #forkongithub {
    display: none;
  }
}
@media (max-width: 410px) {
    #forkongithub a{
        font-size: 0.7rem;
        transform: translateX(150px) rotate(45deg) translate(20px,40px);
    }
}

</style>
<div id="forkongithub"><a href="https://github.com/gfxfundamentals/webgpufundamentals">Fix, Fork, Contribute <?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg width="100%" height="100%" viewBox="0 0 136 133" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" xmlns:serif="http://www.serif.com/" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:2;">
    <g transform="matrix(3.92891,0,0,3.92891,67.867,129.125)">
        <path d="M0,-31.904C-8.995,-31.904 -16.288,-24.611 -16.288,-15.614C-16.288,-8.417 -11.621,-2.312 -5.148,-0.157C-4.333,-0.008 -4.036,-0.511 -4.036,-0.943C-4.036,-1.329 -4.05,-2.354 -4.058,-3.713C-8.589,-2.729 -9.545,-5.897 -9.545,-5.897C-10.286,-7.779 -11.354,-8.28 -11.354,-8.28C-12.833,-9.29 -11.242,-9.27 -11.242,-9.27C-9.607,-9.155 -8.747,-7.591 -8.747,-7.591C-7.294,-5.102 -4.934,-5.821 -4.006,-6.238C-3.858,-7.29 -3.438,-8.008 -2.972,-8.415C-6.589,-8.826 -10.392,-10.224 -10.392,-16.466C-10.392,-18.244 -9.757,-19.698 -8.715,-20.837C-8.883,-21.249 -9.442,-22.905 -8.556,-25.148C-8.556,-25.148 -7.188,-25.586 -4.076,-23.478C-2.777,-23.84 -1.383,-24.02 0.002,-24.026C1.385,-24.02 2.779,-23.84 4.08,-23.478C7.19,-25.586 8.555,-25.148 8.555,-25.148C9.444,-22.905 8.885,-21.249 8.717,-20.837C9.761,-19.698 10.392,-18.244 10.392,-16.466C10.392,-10.208 6.583,-8.831 2.954,-8.428C3.539,-7.925 4.06,-6.931 4.06,-5.411C4.06,-3.234 4.04,-1.477 4.04,-0.943C4.04,-0.507 4.333,0 5.16,-0.159C11.628,-2.318 16.291,-8.419 16.291,-15.614C16.291,-24.611 8.997,-31.904 0,-31.904" style="fill:white;"/>
    </g>
</svg>
</a></div>

</div>


<div class="container">
  <div class="lesson-title">
    <h1>WebGPU from WebGL</h1>
  </div>
  <div class="lesson">
    <div class="lesson-main">
      <div class="warn">
      Warning: WebGPU has not shipped and the spec is still changing.<br><br>
      If you see a problem please <a href="https://github.com/gfxfundamentals/webgpufundamentals">file an issue</a>.
      </div>
      <p>If you&#39;re coming from WebGL to WebGPU it&#39;s worth noting that many of the
concepts are the same. Both WebGL and WebGPU let you run small functions on the
GPU. WebGL has vertex shaders and fragment shaders. WebGPU has the same plus
compute shaders. WebGL uses GLSL as its shading language. WebGPU uses WGSL.
While they are different languages the concepts are mostly the same.</p>
<p>Both APIs have attributes, a way to specify data pulled from buffers and fed
each iteration of a vertex shader. Both APIs have uniforms, a way to specify
values shared by all iterations of a shader function. Both APIs have varyings, a
way to pass data from a vertex shader to a fragment shader and interpolate
between values computed by the vertex shader when rasterizing via a fragment
shader. Both APIs have textures and samplers, ways to provide 2D or 3D data and
sample it (filter multiple pixels into a single value). Both APIs provide ways
to render to textures. And, both have a bunch of settings for how pixels are
blended, how the depth buffer and stencil buffers work, etc...</p>
<p>The biggest difference is WebGL is a stateful API and WebGPU is not. By that I
mean in WebGL there is whole bunch of global state. Which textures are currently
bound, which buffers are currently bound, what the current program is, what the
blending, depth, and stencil settings are. You set those states by calling
various API functions like <code class="notranslate" translate="no">gl.bindBuffer</code> or <code class="notranslate" translate="no">gl.enable</code> etc and they stay
what you set them <em>globally</em> until you change them to something else.</p>
<p>By contrast, In WebGPU there is almost no <em>global</em> state. Instead there concepts
of a <em>pipeline</em> and a <em>render pass</em> which effectively contain most of the state
that was global in WebGL. Which textures, which attributes, which buffers, and
all the various other settings. Any settings you don&#39;t set have default values.
You can&#39;t modify a pipeline. Instead you create them and after that they are
immutable. If you want different settings you need to create another pipeline.
<em>render passes</em> do have some state but that state is local to the render pass.</p>
<p>The second biggest difference is that WebGPU <strong>is lower level</strong> than WebGL. In
WebGL many things connect by names. For example you declare a uniform in GLSL
and you look up its location </p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">loc = gl.getUniformLocation(program, &#39;nameOfUniform&#39;);
</code></pre>
<p>Another example is varyings, in a vertex shader you use
<code class="notranslate" translate="no">varying vec2 v_texcoord</code> or <code class="notranslate" translate="no">out vec2 v_texcoord</code> and in the fragment shader
you declare the corresponding varying naming it <code class="notranslate" translate="no">v_texcoord</code>. The good part of
this is if you mis-type the name you&#39;ll get an error.</p>
<p>WebGPU, on the other hand, everything is entirely connected by index or byte
offset. You don&#39;t create individual uniforms like WebGL, instead you declare
uniform blocks (a structure that declares your uniforms). It&#39;s then up to you to
make sure you manually organize the data you pass to the shader to match that
structure. Note: WebGL2 has the same concept, known as Uniform Blocks, but
WebGL2 also had the concept of uniforms by name. And, even though individual
fields in a WebGL2 Uniform Block needed to be set via byte offsets, (a) you
could query WebGL2 for those offsets and (b) you could still look up the block
locations themselves by name.</p>
<p>In WebGPU on the other hand <strong>EVERYTHING</strong> is by byte offset or index (often
called &#39;<em>location</em>&#39;). That means it&#39;s entirely up to you to keep those locations
in sync and to manually compute byte offsets.</p>
<p>To give a JavaScript analogy:</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">function likeWebGL(inputs) {
  const {position, texcoords, normal, color} = inputs;
  ...
}

function likeWebGPU(inputs) {
  const [position, texcoords, normal, color] = inputs;
  ...
}
</code></pre>
<p>In the <code class="notranslate" translate="no">likeWebGL</code> example above, things are connected by name. We can call
<code class="notranslate" translate="no">likeWebGL</code> like this</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">likeWebGL({normal, color, position});
</code></pre>
<p>Notice because we are connected by names, the order of our parameters does not
matter. Further, we can skip a parameter (<code class="notranslate" translate="no">texcoords</code> in the example above)
assuming the function can run without <code class="notranslate" translate="no">texcoords</code>.</p>
<p>On the other hand with <code class="notranslate" translate="no">likeWebGPU</code></p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">likeWebGPU([position, undefined, normal, color]);
</code></pre>
<p>We pass in our parameters in an array. Notice we have to pass in something for
<code class="notranslate" translate="no">texcoords</code> because if we didn&#39;t things would get out of order and the <code class="notranslate" translate="no">normal</code> we
passed into<code class="notranslate" translate="no">likeWebGPU</code> would become <code class="notranslate" translate="no">texcoords</code> inside the function. Keeping
the code inside (WGSL) and outside (JavaScript/WASM) in sync in WebGPU is
entirely your responsibility.</p>
<h3 id="other-notable-differences">Other notable differences</h3>
<ul>
<li><p>The Canvas</p>
<p>WebGL manages the canvas itself for you. You choose antialias,
preserveDrawingBuffer, stencil, depth, alpha when you create the WebGL context
and after that WebGL manages the canvas itself. All you have to is set
<code class="notranslate" translate="no">canvas.width</code> and <code class="notranslate" translate="no">canvas.height</code>.</p>
<p>WebGPU you have to do all of that yourself. You create the canvas&#39;s
drawingbuffer (with or without alpha) and if you want a depth buffer you create
that yourself too (with or without a stencil buffer). If you want to resize you
need to delete the old ones and create new ones yourself.</p>
</li>
<li><p>WebGPU does not generate mipmaps.</p>
<p>In WebGL you could create a texture&#39;s level 0 mip and then call
<code class="notranslate" translate="no">gl.generateMipmap</code> and WebGL would generate all the other mip levels. WebGPU
has no such function. If you want mips for your textures you have to generate
them yourself.</p>
</li>
<li><p>WebGPU requires samplers</p>
<p>In WebGL1, samplers did not exist or to put it another way, samplers were handled
by WebGL internally. In WebGL2 using samplers was optional. In WebGPU
samplers are required.</p>
</li>
</ul>
<h2 id="let-s-compare-webgl-to-webgpu">Let&#39;s compare WebGL to WebGPU</h2>
<h3 id="shaders">Shaders</h3>
<p>Here is a shader that draws textured, lit, triangles. One in GLSL and the other
in WGSL.</p>
<div class="webgpu_center compare"><div><div>GLSL</div><pre class="prettyprint lang-javascript"><code class="notranslate" translate="no">
const vSrc = `
uniform mat4 u_worldViewProjection;
uniform mat4 u_worldInverseTranspose;

attribute vec4 a_position;
attribute vec3 a_normal;
attribute vec2 a_texcoord;

varying vec2 v_texCoord;
varying vec3 v_normal;

void main() {
  gl_Position = u_worldViewProjection * a_position;
  v_texCoord = a_texcoord;
  v_normal = (u_worldInverseTranspose * vec4(a_normal, 0)).xyz;
}
`;

const fSrc = `
precision highp float;

varying vec2 v_texCoord;
varying vec3 v_normal;

uniform sampler2D u_diffuse;
uniform vec3 u_lightDirection;

void main() {
  vec4 diffuseColor = texture2D(u_diffuse, v_texCoord);
  vec3 a_normal = normalize(v_normal);
  float l = dot(a_normal, u_lightDirection) * 0.5 + 0.5;
  gl_FragColor = vec4(diffuseColor.rgb * l, diffuseColor.a);
}
`;
</code></pre>
</div><div>
<div>WGSL</div>
<pre class="prettyprint lang-javascript"><code class="notranslate" translate="no">
const shaderSrc = `
struct VSUniforms {
  worldViewProjection: mat4x4<f32>;
  worldInverseTranspose: mat4x4<f32>;
};
[[group(0), binding(0)]] var<uniform> vsUniforms: VSUniforms;

struct MyVSInput {
    [[location(0)]] position: vec4<f32>;
    [[location(1)]] normal: vec3<f32>;
    [[location(2)]] texcoord: vec2<f32>;
};

struct MyVSOutput {
  [[builtin(position)]] position: vec4<f32>;
  [[location(0)]] normal: vec3<f32>;
  [[location(1)]] texcoord: vec2<f32>;
};

[[stage(vertex)]]
fn myVSMain(v: MyVSInput) -> MyVSOutput
{
  var vsOut: MyVSOutput;

  vsOut.position = vsUniforms.worldViewProjection * v.position;
  vsOut.normal = (vsUniforms.worldInverseTranspose * vec4<f32>(v.normal, 0.0)).xyz;
  vsOut.texcoord = v.texcoord;
  return vsOut;
}

struct FSUniforms {
  lightDirection: vec3<f32>;
};

[[group(0), binding(1)]] var<uniform> fsUniforms: FSUniforms;
[[group(0), binding(2)]] var diffuseSampler: sampler;
[[group(0), binding(3)]] var diffuseTexture: texture_2d<f32>;

[[stage(fragment)]]
fn myFSMain(v: MyVSOutput) -> [[location(0)]] vec4<f32>
{
  var diffuseColor = textureSample(diffuseTexture, diffuseSampler, v.texcoord);
  var a_normal = normalize(v.normal);
  var l = dot(a_normal, fsUniforms.lightDirection) * 0.5 + 0.5;
  return vec4<f32>(diffuseColor.rgb * l, diffuseColor.a);
}
`;
</code></pre></div></div>

<p>Notice in many ways they aren&#39;t all that different. The core parts of each
function are very similar. <code class="notranslate" translate="no">vec4</code> in GLSL becomes <code class="notranslate" translate="no">vec4&lt;f32&gt;</code> in WGSL, <code class="notranslate" translate="no">mat4</code>
becomes <code class="notranslate" translate="no">mat4x4&lt;f32&gt;</code>. WGSL has the concept <code class="notranslate" translate="no">var</code> which means a variable&#39;s type
becomes the type of the expression on the right where as GLSL required you to
specify the type. In other words in GLSL</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-glsl">vec4 color = texture(someTexture, someTextureCoord);
</code></pre>
<p>Above you needed to declare <code class="notranslate" translate="no">color</code> as a <code class="notranslate" translate="no">vec4</code> but in WGSL you can do either of these</p>
<pre class="prettyprint notranslate" translate="no"><code class="notranslate" translate="no">vec4&lt;f32&gt; color = textureSampler(someTexture, someSampler, someTextureCoord);
</code></pre><p>or</p>
<pre class="prettyprint notranslate" translate="no"><code class="notranslate" translate="no">var color = textureSampler(someTexture, someSampler, someTextureCoord);
</code></pre><p>In both cases <code class="notranslate" translate="no">color</code> is a <code class="notranslate" translate="no">vec4&lt;f32&gt;</code>.</p>
<p>On the other hand, the biggest difference is all of the <code class="notranslate" translate="no">[[???]]</code> parts. Each
one is declaring exactly where that particular piece of data is coming from. For
example, notice that uniforms in the vertex shader and uniforms the fragment
shader declare their <code class="notranslate" translate="no">[[group(?), binding(?)]]</code> and that it&#39;s up to you to make
sure they don&#39;t clash. Above the vertex shader uses <code class="notranslate" translate="no">binding(0)</code> and the
fragment shader <code class="notranslate" translate="no">binding(1)</code>, <code class="notranslate" translate="no">binding(2)</code>, <code class="notranslate" translate="no">binding(3)</code> In the example above
there are 2 uniform blocks. We could have used 1. I chose to use 2 to more
separate the vertex shader from the fragment shader.</p>
<p>Another difference between WebGL and WebGPU is that in WebGPU you can put
multiple shaders in the same source. In WebGL a shader&#39;s entry point was always
called <code class="notranslate" translate="no">main</code> but in WebGPU when you use a shader you specify which function to
call.</p>
<p>Notice in WebGPU the attributes are declared as parameters to the vertex shader
function vs GLSL where they are declared as globals outside the function.</p>
<p>For varyings, in GLSL they are also declared as global variables where as in
WGSL you declare a structure with locations for each field, you declare your
vertex shader as returning that structure and you return an instance of that
structure in the function itself. In the fragment shader you declare your
function as taking these inputs.</p>
<p>In the code above uses the same structure for both the vertex shaders output and
the fragment shader&#39;s input but there&#39;s not requirement to use the same
structure. All that&#39;s required is that the locations match. For example this
would work:</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-wgsl">struct MyFSInput {
  [[location(0)]] normal: vec3&lt;f32&gt;;
  [[location(1)]] texcoord: vec2&lt;f32&gt;;
};

[[stage(fragment)]]
fn myFSMain(v: MyFSInput) -&gt; [[location(0)]] vec4&lt;f32&gt;
{
  var diffuseColor = textureSample(diffuseTexture, diffuseSampler, v.texcoord);
  var a_normal = normalize(v.normal);
  var l = dot(a_normal, fsUniforms.lightDirection) * 0.5 + 0.5;
  return vec4&lt;f32&gt;(diffuseColor.rgb * l, diffuseColor.a);
}
</code></pre>
<p>This would also work</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-wgsl">[[stage(fragment)]]
fn myFSMain(
  [[location(0)]] normal: vec3&lt;f32&gt;,
  [[location(1)]] texcoord: vec2&lt;f32&gt;,
) -&gt; [[location(0)]] vec4&lt;f32&gt;
{
  var diffuseColor = textureSample(diffuseTexture, diffuseSampler, texcoord);
  var a_normal = normalize(normal);
  var l = dot(a_normal, fsUniforms.lightDirection) * 0.5 + 0.5;
  return vec4&lt;f32&gt;(diffuseColor.rgb * l, diffuseColor.a);
}
</code></pre>
<p>Again, what matters is the that the locations match.</p>
<h3 id="getting-the-api">Getting the API</h3>
<div class="webgpu_center compare">
  <div>
    <div>WebGL</div>
<pre class="prettyprint lang-javascript"><code class="notranslate" translate="no">
function main() {
  const gl = document.querySelector('canvas').getContext('webgl');
  if (!gl) {
    alert('need webgl');
    return;
  }
}

main();
</code></pre>
  </div>
  <div>
    <div>WebGPU</div>
<pre class="prettyprint lang-javascript"><code class="notranslate" translate="no">
async function main() {
  const gpu = navigator.gpu;
  if (!gpu) {
    alert('this browser does not support webgpu');
    return;
  }

  const adapter = await gpu.requestAdapter();
  if (!adapter) {
    alert('this browser appears to support WebGPU but it\'s disabled');
    return;
  }
  const device = await adapter.requestDevice();

...
}

main();
</code></pre>
  </div>
</div>

<p>Here, <code class="notranslate" translate="no">adapter</code> represents the GPU itself where as <code class="notranslate" translate="no">device</code> represents
an instance of the API on that GPU.</p>
<p>Probably the biggest difference here is that getting the API in WebGPU
is asynchronous.</p>
<h3 id="compiling-shaders">Compiling shaders</h3>
<div class="webgpu_center compare">
  <div>
    <div>WebGL</div>
<pre class="prettyprint lang-javascript"><code class="notranslate" translate="no">
function createShader(gl, type, source) {
  const sh = gl.createShader(type);
  gl.shaderSource(sh, source);
  gl.compileShader(sh);
  if (!gl.getShaderParameter(sh, gl.COMPILE_STATUS)) {
    throw new Error(gl.getShaderInfoLog(sh));
  }
  return sh;
}

function createProgram(gl, vSrc, fSrc) {
  const vs = createShader(gl, gl.VERTEX_SHADER, vSrc);
  const fs = createShader(gl, gl.FRAGMENT_SHADER, fSrc);
  const prg = gl.createProgram();
  gl.attachShader(prg, vs);
  gl.attachShader(prg, fs);
  gl.linkProgram(prg);
  if (!gl.getProgramParameter(prg, gl.LINK_STATUS)) {
    throw new Error(gl.getProgramInfoLog(prg));
  }
  return prg;
}

const program = createProgram(gl, vSrc, fSrc);
</code></pre>
  </div>
  <div>
    <div>WebGPU</div>
<pre class="prettyprint lang-javascript"><code class="notranslate" translate="no">
function showErrorsSimple(code, info) {
  let hasError = false;
  info.messages.forEach(m => {
    console[m.type](`${m.lineNum}:${m.linePos}:${m.message}`);
    hasError |= m.type === 'error';
  });
  return hasError;
}

async function createShaderModule(device, code) {
  const shader = device.createShaderModule({code});
  const info = await shader.compilationInfo();
  if (info.messages.length) {
    const hasError = showErrorsSimple(code, info);
    if (hasError) {
      throw new Error('can not compile shader');
    }
  }
  return shader;
}

const shaderModule = await createShaderModule(device, shaderSrc);
</code></pre>
  </div>
</div>

<p>A minor difference, unlike WebGL, we can compile multiple shaders at once.</p>
<p>The code above is probably a little controversial. In WebGL if your shader
didn&#39;t compile it is up to you to check vs <code class="notranslate" translate="no">gl.getShaderParameter</code> and then if
it failed, pull out the error messages with a call to <code class="notranslate" translate="no">gl.getShaderInfoLog</code>. If
you didn&#39;t do this no errors are shown. You&#39;d likely just get an error later
when you tried to use the shader program.</p>
<p>In WebGPU, according to the spec, it&#39;s similar, but, at least at the moment,
most implementations print shader complication errors to the JavaScript console
even if you don&#39;t ask for them.</p>
<p>Further, the code above waits for the error message, which is slower than
not waiting. (The same is true in WebGL). The point being there&#39;s less reason
to check for the errors yourself since, at least at the moment, the browser
will show you the errors automatically, so many WebGPU example don&#39;t check.
But, in WebGPU you can only get the errors asynchronously, so you have to
choose. Do you want to <code class="notranslate" translate="no">await</code> for the errors, do you want to get them
<em>out of band</em>, or do you just want to ignore them.</p>
<p>A big difference is that errors are structured in WebGPU. In WebGL it was
just a string. In WebGPU it&#39;s an array of messages and those messages may or
may not be errors. To show them you have to loop through them.</p>
<h3 id="preparing-for-uniforms">Preparing for uniforms</h3>
<div class="webgpu_center compare">
  <div>
    <div>WebGL</div>
<pre class="prettyprint lang-javascript"><code class="notranslate" translate="no">
const u_lightDirectionLoc = gl.getUniformLocation(program, 'u_lightDirection');
const u_diffuseLoc = gl.getUniformLocation(program, 'u_diffuse');
const u_worldInverseTransposeLoc = gl.getUniformLocation(program, 'u_worldInverseTranspose');
const u_worldViewProjectionLoc = gl.getUniformLocation(program, 'u_worldViewProjection');
</code></pre>
  </div>
  <div>
    <div>WebGPU</div>
<pre class="prettyprint lang-javascript"><code class="notranslate" translate="no">
const vUniformBufferSize = 2 * 16 * 4; // 2 mat4s * 16 floats per mat * 4 bytes per float
const fUniformBufferSize = 3 * 4;      // 1 vec3 * 3 floats per vec3 * 4 bytes per float

const vsUniformBuffer = device.createBuffer({
  size: vUniformBufferSize,
  usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
});
const fsUniformBuffer = device.createBuffer({
  size: fUniformBufferSize,
  usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
});
const vsUniformValues = new Float32Array(2 * 16); // 2 mat4s
const worldViewProjection = vsUniformValues.subarray(0, 16);
const worldInverseTranspose = vsUniformValues.subarray(16, 32);
const fsUniformValues = new Float32Array(3);  // 1 vec3
const lightDirection = fsUniformValues.subarray(0, 3);
</code></pre>
  </div>
</div>

<p>In WebGL we lookup the locations of the uniforms. In WebGPU we create
buffers to hold the values of the uniforms. The code above then creates
TypedArray views into larger CPU side TypedArrays that hold the values
for the uniforms. Notice <code class="notranslate" translate="no">vUniformBufferSize</code> and <code class="notranslate" translate="no">fUniformBufferSize</code>
are hand computed. Similarly when creating views into type typed arrays
the offsets and sizes are hand computed. It&#39;s entirely up to use to
do those calculations. Unlike WebGL, WebGPU provides no API to query these offsets
and sizes.</p>
<p>Note, a similar process exists for WebGL2 using Uniform Blocks but if
you&#39;ve never used Uniform Blocks then this will be new.</p>
<h3 id="creating-buffers">Creating Buffers</h3>
<div class="webgpu_center compare">
  <div>
    <div>WebGL</div>
<pre class="prettyprint lang-javascript"><code class="notranslate" translate="no">
function createBuffer(gl, data, type = gl.ARRAY_BUFFER) {
  const buf = gl.createBuffer();
  gl.bindBuffer(type, buf);
  gl.bufferData(type, data, gl.STATIC_DRAW);
  return buf;
}

const positions = new Float32Array([1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, 1, -1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, -1, -1, -1, -1]);
const normals   = new Float32Array([1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, -1, 0, 0, -1, 0, 0, -1, 0, 0, -1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, -1, 0, 0, -1, 0, 0, -1, 0, 0, -1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, -1, 0, 0, -1, 0, 0, -1, 0, 0, -1]);
const texcoords = new Float32Array([1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1]);
const indices   = new Uint16Array([0, 1, 2, 0, 2, 3, 4, 5, 6, 4, 6, 7, 8, 9, 10, 8, 10, 11, 12, 13, 14, 12, 14, 15, 16, 17, 18, 16, 18, 19, 20, 21, 22, 20, 22, 23]);

const positionBuffer = createBuffer(gl, positions);
const normalBuffer = createBuffer(gl, normals);
const texcoordBuffer = createBuffer(gl, texcoords);
const indicesBuffer = createBuffer(gl, indices, gl.ELEMENT_ARRAY_BUFFER);
</code></pre>
  </div>
  <div>
    <div>WebGPU</div>
<pre class="prettyprint lang-javascript"><code class="notranslate" translate="no">
function createBuffer(device, data, usage) {
  const buffer = device.createBuffer({
    size: data.byteLength,
    usage,
    mappedAtCreation: true,
  });
  const dst = new data.constructor(buffer.getMappedRange());
  dst.set(data);
  buffer.unmap();
  return buffer;
}

const positions = new Float32Array([1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, 1, -1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, -1, -1, -1, -1]);
const normals   = new Float32Array([1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, -1, 0, 0, -1, 0, 0, -1, 0, 0, -1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, -1, 0, 0, -1, 0, 0, -1, 0, 0, -1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, -1, 0, 0, -1, 0, 0, -1, 0, 0, -1]);
const texcoords = new Float32Array([1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1]);
const indices   = new Uint16Array([0, 1, 2, 0, 2, 3, 4, 5, 6, 4, 6, 7, 8, 9, 10, 8, 10, 11, 12, 13, 14, 12, 14, 15, 16, 17, 18, 16, 18, 19, 20, 21, 22, 20, 22, 23]);

const positionBuffer = createBuffer(device, positions, GPUBufferUsage.VERTEX);
const normalBuffer = createBuffer(device, normals, GPUBufferUsage.VERTEX);
const texcoordBuffer = createBuffer(device, texcoords, GPUBufferUsage.VERTEX);
const indicesBuffer = createBuffer(device, indices, GPUBufferUsage.INDEX);
</code></pre>
  </div>
</div>

<p>You can see, at a glance, these are not too different. You call different
functions but otherwise it&#39;s pretty similar.</p>
<h3 id="creating-a-texture">Creating a Texture</h3>
<div class="webgpu_center compare">
  <div>
    <div>WebGL</div>
<pre class="prettyprint lang-javascript"><code class="notranslate" translate="no">
const tex = gl.createTexture();
gl.bindTexture(gl.TEXTURE_2D, tex);
gl.texImage2D(
    gl.TEXTURE_2D,
    0,    // level
    gl.RGBA,
    2,    // width
    2,    // height
    0,
    gl.RGBA,
    gl.UNSIGNED_BYTE,
    new Uint8Array([
      255, 255, 128, 255,
      128, 255, 255, 255,
      255, 128, 255, 255,
      255, 128, 128, 255,
    ]));
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
</code></pre>
  </div>
  <div>
    <div>WebGPU</div>
<pre class="prettyprint lang-javascript"><code class="notranslate" translate="no">
const tex = device.createTexture({
  size: [2, 2, 1],
  format: 'rgba8unorm',
  usage:
    GPUTextureUsage.TEXTURE_BINDING |
    GPUTextureUsage.COPY_DST,
});
device.queue.writeTexture(
    { texture: tex },
    new Uint8Array([
      255, 255, 128, 255,
      128, 255, 255, 255,
      255, 128, 255, 255,
      255, 128, 128, 255,
    ]),
    { bytesPerRow: 8, rowsPerImage: 2 },
    { width: 2, height: 2 },
);

const sampler = device.createSampler({
  magFilter: 'nearest',
  minFilter: 'nearest',
});
</code></pre>
  </div>
</div>

<p>Again, not all that different. One difference is there are usage flags in WebGPU
that you need to set depending on what you plan to do with the texture. Another
is that in WebGPU we need to create a sampler which is optional in WebGL</p>
<h3 id="setting-up-a-pipeline">Setting up a Pipeline</h3>
<p>Several things that happen in WebGL are combined into one thing in WebGPU
when creating a pipeline. For example, linking the shaders, setting up
attributes, choosing the draw mode (points, line, triangles), setting up
how the depth buffer is used. </p>
<p>Here&#39;s the code.</p>
<div class="webgpu_center compare">
  <div>
    <div>WebGL</div>
<pre class="prettyprint lang-javascript"><code class="notranslate" translate="no">
gl.linkProgram(prg);

...

gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
gl.vertexAttribPointer(positionLoc, 3, gl.FLOAT, false, 0, 0);
gl.enableVertexAttribArray(positionLoc);

gl.bindBuffer(gl.ARRAY_BUFFER, normalBuffer);
gl.vertexAttribPointer(normalLoc, 3, gl.FLOAT, false, 0, 0);
gl.enableVertexAttribArray(normalLoc);

gl.bindBuffer(gl.ARRAY_BUFFER, texcoordBuffer);
gl.vertexAttribPointer(texcoordLoc, 2, gl.FLOAT, false, 0, 0);
gl.enableVertexAttribArray(texcoordLoc);

....

gl.enable(gl.DEPTH_TEST);
gl.enable(gl.CULL_FACE);
</code></pre>
  </div>
  <div>
    <div>WebGPU</div>
<pre class="prettyprint lang-javascript"><code class="notranslate" translate="no">
const pipeline = device.createRenderPipeline({
  vertex: {
    module: shaderModule,
    entryPoint: 'myVSMain',
    buffers: [
      // position
      {
        arrayStride: 3 * 4, // 3 floats, 4 bytes each
        attributes: [
          {shaderLocation: 0, offset: 0, format: 'float32x3'},
        ],
      },
      // normals
      {
        arrayStride: 3 * 4, // 3 floats, 4 bytes each
        attributes: [
          {shaderLocation: 1, offset: 0, format: 'float32x3'},
        ],
      },
      // texcoords
      {
        arrayStride: 2 * 4, // 2 floats, 4 bytes each
        attributes: [
          {shaderLocation: 2, offset: 0, format: 'float32x2',},
        ],
      },
    ],
  },
  fragment: {
    module: shaderModule,
    entryPoint: 'myFSMain',
    targets: [
      {format: presentationFormat},
    ],
  },
  primitive: {
    topology: 'triangle-list',
    cullMode: 'back',
  },
  depthStencil: {
    depthWriteEnabled: true,
    depthCompare: 'less',
    format: 'depth24plus',
  },
  ...(canvasInfo.sampleCount > 1 && {
      multisample: {
        count: canvasInfo.sampleCount,
      },
  }),
});
</code></pre>
  </div>
</div>

<p>Parts to note:</p>
<p>Shader linking happens when you call <code class="notranslate" translate="no">createRenderPipeline</code> and in fact
<code class="notranslate" translate="no">createRenderPipeline</code> is a slow call as your shaders might be adjusted
internally depending on the settings. You can see, for <code class="notranslate" translate="no">vertex</code> and <code class="notranslate" translate="no">fragment</code>
we specify a shader <code class="notranslate" translate="no">module</code> and specify which function to call via <code class="notranslate" translate="no">entryPoint</code>.
WebGPU then needs to make sure those 2 functions are compatible with each other.</p>
<p>In WebGL we call <code class="notranslate" translate="no">gl.vertexAttribPointer</code> to attach the current ARRAY_BUFFER
buffer to an attribute <em>and</em> to specify how to pull data out of that buffer. In
WebGPU we only specify how to pull data out of buffers when creating the
pipeline. We specify what buffers to use later.</p>
<p>In the example above you can see <code class="notranslate" translate="no">buffers</code> is an array of objects.
Those objects are called <code class="notranslate" translate="no">GPUVertexBufferLayout</code>. Within each one is
an array of attributes. Here we&#39;re setting up to get our data from
3 different buffers. If we interleaved the data into one buffer
we&#39;d only need one <code class="notranslate" translate="no">GPUVertexBufferLayout</code> but its <code class="notranslate" translate="no">attribute</code> array
would have 3 entries.</p>
<p>Also note here is a place where we have to match <code class="notranslate" translate="no">shaderLocation</code> to
what we used in the shader.</p>
<p>In WebGPU we setup the <code class="notranslate" translate="no">primitive</code>, cull mode, and depth settings here.
That means if we want to draw something with any of those settings different,
for example if we want to draw some geometry with triangles and later with
lines, we have to create multiple pipelines.</p>
<p>The last part <code class="notranslate" translate="no">multisample</code> we need if we&#39;re drawing to a multi-sampled
destination texture. I put that in here because by default, WebGL will use a
multi sampled texture for the canvas. To emulate that requires adding a
<code class="notranslate" translate="no">multisample</code> property. <code class="notranslate" translate="no">presentationFormat</code> and <code class="notranslate" translate="no">canvasInfo.sampleCount</code> areß
something we&#39;ll below. Similarly</p>
<h3 id="preparing-to-draw">Preparing to draw</h3>
<p>In WebGL we&#39;d get straight to drawing at this point but in WebGPU we have some
work left.</p>
<p>We need to create a bind group. This lets us specify what resources our
shaders will use</p>
<div class="webgpu_center compare">
  <div>
    <div>WebGL</div>
<pre class="prettyprint lang-javascript"><code class="notranslate" translate="no">
// happens at render time
gl.activeTexture(gl.TEXTURE0);
gl.bindTexture(gl.TEXTURE_2D, tex);
</code></pre>
  </div>
  <div>
    <div>WebGPU</div>
<pre class="prettyprint lang-javascript"><code class="notranslate" translate="no">
// can happen at init time
const bindGroup = device.createBindGroup({
  layout: pipeline.getBindGroupLayout(0),
  entries: [
    { binding: 0, resource: { buffer: vsUniformBuffer } },
    { binding: 1, resource: { buffer: fsUniformBuffer } },
    { binding: 2, resource: sampler },
    { binding: 3, resource: tex.createView() },
  ],
});
</code></pre>
  </div>
</div>

<p>Again, notice the <code class="notranslate" translate="no">binding</code> add group must match what we specified in our shaders.</p>
<p>In WebGPU we also create a render pass descriptor vs WebGL where these
settings are set via stateful API calls or handled automatically.</p>
<div class="webgpu_center compare">
  <div>
    <div>WebGL</div>
<pre class="prettyprint lang-javascript"><code class="notranslate" translate="no">
gl.clearColor(0.5, 0.5, 0.5, 1.0);
gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);
</code></pre>
  </div>
  <div>
    <div>WebGPU</div>
<pre class="prettyprint lang-javascript"><code class="notranslate" translate="no">
const renderPassDescriptor = {
  colorAttachments: [
    {
      // view: undefined, // Assigned later
      // resolveTarget: undefined, // Assigned Later
      loadValue: { r: 0.5, g: 0.5, b: 0.5, a: 1.0 },
      storeOp: 'store',
    },
  ],
  depthStencilAttachment: {
    // view: undefined,  // Assigned later
    depthLoadValue: 1.0,
    depthStoreOp: 'store',
    stencilLoadValue: 0,
    stencilStoreOp: 'store',
  },
};
</code></pre>
  </div>
</div>

<p>Note that many of the settings in WebGPU are related to where we want to render.
In WebGL, when rendering to the canvas, all of this was handled for us. When
rendering to a framebuffer these settings are the equivalent of calls to
<code class="notranslate" translate="no">gl.framebufferTexture2D</code> and/or <code class="notranslate" translate="no">gl.framebufferRenderbuffer</code>.</p>
<h3 id="setting-uniforms">Setting Uniforms</h3>
<div class="webgpu_center compare">
  <div>
    <div>WebGL</div>
<pre class="prettyprint lang-javascript"><code class="notranslate" translate="no">
gl.uniform3fv(u_lightDirectionLoc, v3.normalize([1, 8, -10]));
gl.uniform1i(u_diffuseLoc, 0);
gl.uniformMatrix4fv(u_worldInverseTransposeLoc, false, m4.transpose(m4.inverse(world)));
gl.uniformMatrix4fv(u_worldViewProjectionLoc, false, m4.multiply(viewProjection, world));
</code></pre>
  </div>
  <div>
    <div>WebGPU</div>
<pre class="prettyprint lang-javascript"><code class="notranslate" translate="no">
m4.transpose(m4.inverse(world), worldInverseTranspose);
m4.multiply(viewProjection, world, worldViewProjection);

v3.normalize([1, 8, -10], lightDirection);

device.queue.writeBuffer(
  vsUniformBuffer,
  0,
  vsUniformValues.buffer,
  vsUniformValues.byteOffset,
  vsUniformValues.byteLength,
);
device.queue.writeBuffer(
  fsUniformBuffer,
  0,
  fsUniformValues.buffer,
  fsUniformValues.byteOffset,
  fsUniformValues.byteLength,
);
</code></pre>
  </div>
</div>

<p>In the WebGL case we compute a value and pass it to <code class="notranslate" translate="no">gl.uniform???</code> with
the appropriate location.</p>
<p>In the WebGPU case we write values into our typed arrays and then copy the
contents of those typed arrays to the corresponding GPU buffers.</p>
<p>Note: In WebGL2, if we were using Uniform Blocks, this process is almost
exactly the same except we&#39;d call <code class="notranslate" translate="no">gl.bufferSubData</code> to upload the typed array
contents.</p>
<h3 id="resizing-the-drawing-buffer">Resizing the drawing buffer</h3>
<p>As mentioned near the start of the article, this is one place that WebGL just
handled for us but in WebGPU we need to do ourselves.</p>
<div class="webgpu_center compare">
  <div>
    <div>WebGL</div>
<pre class="prettyprint lang-javascript"><code class="notranslate" translate="no">
function resizeCanvasToDisplaySize(canvas) {
  const width = canvas.clientWidth;
  const height = canvas.clientHeight;
  const needResize = width !== canvas.width || height !== canvas.height;
  if (needResize) {
    canvas.width = width;
    canvas.height = height;
  }
  return needResize;
}
</code></pre>
  </div>
  <div>
    <div>WebGPU</div>
<pre class="prettyprint lang-javascript"><code class="notranslate" translate="no">
// At init time
const canvas = document.querySelector('canvas');
const context = canvas.getContext('webgpu');

const presentationFormat = context.getPreferredFormat(adapter);
const presentationSize = [300, 150];  // default canvas size

const canvasInfo = {
  canvas,
  context,
  presentationSize,
  presentationFormat,
  // these are filled out in resizeToDisplaySize
  renderTarget: undefined,
  renderTargetView: undefined,
  depthTexture: undefined,
  depthTextureView: undefined,
  sampleCount: 4,  // can be 1 or 4
};

// --- At render time ---

function resizeToDisplaySize(device, canvasInfo) {
  const {
    canvas,
    context,
    renderTarget,
    presentationSize,
    presentationFormat,
    depthTexture,
    sampleCount,
  } = canvasInfo;
  const width = Math.min(device.limits.maxTextureDimension2D, canvas.clientWidth);
  const height = Math.min(device.limits.maxTextureDimension2D, canvas.clientHeight);

  const needResize = !canvasInfo.renderTarget ||
                     width !== presentationSize[0] ||
                     height !== presentationSize[1];
  if (needResize) {
    if (renderTarget) {
      renderTarget.destroy();
    }
    if (depthTexture) {
      depthTexture.destroy();
    }

    presentationSize[0] = width;
    presentationSize[1] = height;

    context.configure({
      device,
      format: presentationFormat,
      size: presentationSize,
    });

    if (sampleCount > 1) {
      const newRenderTarget = device.createTexture({
        size: presentationSize,
        format: presentationFormat,
        sampleCount,
        usage: GPUTextureUsage.RENDER_ATTACHMENT,
      });
      canvasInfo.renderTarget = newRenderTarget;
      canvasInfo.renderTargetView = newRenderTarget.createView();
    }

    const newDepthTexture = device.createTexture({
      size: presentationSize,
      format: 'depth24plus',
      sampleCount,
      usage: GPUTextureUsage.RENDER_ATTACHMENT,
    });
    canvasInfo.depthTexture = newDepthTexture;
    canvasInfo.depthTextureView = newDepthTexture.createView();
  }
  return needResize;
}
</code></pre>
  </div>
</div>

<p>You can see above there&#39;s a bunch of work to do. If we need to resize, 
we need to manually destroy the old textures (color and depth) and create
new ones. We also need to check that we don&#39;t go over the limits, something
WebGL handled for us, at least for the canvas.</p>
<p>Above, the property <code class="notranslate" translate="no">sampleCount</code> effectively becomes the <code class="notranslate" translate="no">antialias</code> property
of the WebGL context&#39;s creation attributes. <code class="notranslate" translate="no">sampleCount: 4</code> would be the equivalent of <code class="notranslate" translate="no">antialias: true</code> (the default), were as <code class="notranslate" translate="no">sampleCount: 1</code> would be
the equivalent of <code class="notranslate" translate="no">antialias: false</code> when creating the WebGL context.</p>
<h3 id="drawing">Drawing</h3>
<div class="webgpu_center compare">
  <div>
    <div>WebGL</div>
<pre class="prettyprint lang-javascript"><code class="notranslate" translate="no">
gl.viewport(0, 0, gl.canvas.width, gl.canvas.height);
gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

...
gl.activeTexture(gl.TEXTURE0);
gl.bindTexture(gl.TEXTURE_2D, tex);

gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
gl.vertexAttribPointer(positionLoc, 3, gl.FLOAT, false, 0, 0);
gl.enableVertexAttribArray(positionLoc);

gl.bindBuffer(gl.ARRAY_BUFFER, normalBuffer);
gl.vertexAttribPointer(normalLoc, 3, gl.FLOAT, false, 0, 0);
gl.enableVertexAttribArray(normalLoc);

gl.bindBuffer(gl.ARRAY_BUFFER, texcoordBuffer);
gl.vertexAttribPointer(texcoordLoc, 2, gl.FLOAT, false, 0, 0);
gl.enableVertexAttribArray(texcoordLoc);

...

gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, indicesBuffer);

gl.drawElements(gl.TRIANGLES, 6 * 6, gl.UNSIGNED_SHORT, 0);
</code></pre>
  </div>
  <div>
    <div>WebGPU</div>
<pre class="prettyprint lang-javascript"><code class="notranslate" translate="no">
if (canvasInfo.sampleCount === 1) {
    const colorTexture = context.getCurrentTexture();
    renderPassDescriptor.colorAttachments[0].view = colorTexture.createView();
} else {
  renderPassDescriptor.colorAttachments[0].view = canvasInfo.renderTargetView;
  renderPassDescriptor.colorAttachments[0].resolveTarget = context.getCurrentTexture().createView();
}
renderPassDescriptor.depthStencilAttachment.view = canvasInfo.depthTextureView;

const commandEncoder = device.createCommandEncoder();
const passEncoder = commandEncoder.beginRenderPass(renderPassDescriptor);
passEncoder.setPipeline(pipeline);
passEncoder.setBindGroup(0, bindGroup);
passEncoder.setVertexBuffer(0, positionBuffer);
passEncoder.setVertexBuffer(1, normalBuffer);
passEncoder.setVertexBuffer(2, texcoordBuffer);
passEncoder.setIndexBuffer(indicesBuffer, 'uint16');
passEncoder.drawIndexed(indices.length);
passEncoder.endPass();
device.queue.submit([commandEncoder.finish()]);
</code></pre>
  </div>
</div>

<p>Note that I repeated the WebGL attribute setup code here. In WebGL, this can happen at init time or at render time. In WebGPU we setup how to pull data
out of the buffers at init time but we set the actual buffers to use at
render time.</p>
<p>In WebGPU, we need to update our render pass descriptor to use the textures
we may have just updated in <code class="notranslate" translate="no">resizeToDisplaySize</code>. Then we need to create a 
command encoder and begin a render pass.</p>
<p>In the render pass we set the pipeline, which is kind of like the equivalent of
<code class="notranslate" translate="no">gl.useProgram</code>. We then set our bind group which supplies our sampler, texture,
and the 2 buffers for our uniforms. We set the vertex buffers to match
what we declared earlier. Finally we set an index buffer can call <code class="notranslate" translate="no">drawIndexed</code>
which is the equivalent of calling <code class="notranslate" translate="no">gl.drawElements</code>.</p>
<p>In WebGL we needed to call <code class="notranslate" translate="no">gl.viewport</code>. In WebGPU the pass encoder defaults
to a viewport that matches the size of the attachments so unless we want a
different viewport setting we don&#39;t have to set a viewport separately.</p>
<p>In WebGL we called <code class="notranslate" translate="no">gl.clear</code> to clear the canvas. In WebGPU we had previously
set that up when creating our render pass descriptor.</p>
<h2 id="working-examples-">Working Examples:</h2>
<p>WebGL</p>
<p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgl-cube.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgl-cube.html" target="_blank">click here to open in a separate window</a>
</div>

</p>
<p>WebGPU</p>
<p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-cube.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-cube.html" target="_blank">click here to open in a separate window</a>
</div>

</p>
<p>If you were already familiar with WebGL then I hope this article was useful.</p>

    </div>
    <div class="lesson-sidebar">
        <select class="language">
    <option value="/webgpu/lessons/webgpu-from-webgl.html" selected>English</a>
</select>


        <div id="toc">
          <ul>  <li>Basics</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-fundamentals.html">Fundamentals</a></li>
        </ul>
  <li>Mics</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-from-webgl.html">WebGPU from WebGL</a></li>
        </ul></ul>
<ul>
  <li><a href="https://github.com/gfxfundamentals/webgpufundamentals">github</a></li>
</ul>

        </div>
    </div>
    <div class="lesson-comments">
        
    <div>Questions? <a href="http://stackoverflow.com/questions/tagged/webgpu">Ask on stackoverflow</a>.</div>
    <div>
       <a href="https://github.com/gfxfundamentals/webgpufundamentals/issues/new?assignees=&labels=suggested+topic&template=suggest-topic.md&title=%5BSUGGESTION%5D">Suggestion</a>?
       <a href="https://github.com/gfxfundamentals/webgpufundamentals/issues/new?assignees=&labels=&template=request.md&title=">Request</a>?
       <a href="https://github.com/gfxfundamentals/webgpufundamentals/issues/new?assignees=&labels=bug+%2F+issue&template=bug-issue-report.md&title=">Issue</a>?
       <a href="https://github.com/gfxfundamentals/webgpufundamentals/issues/new?assignees=&labels=bug+%2F+issue&template=bug-issue-report.md&title=">Bug</a>?
    </div>
    <div class="lesson-comment-notes">
       Use <b>&lt;pre&gt;&lt;code&gt;</b>code goes here<b>&lt;/code&gt;&lt;/pre&gt;</b> for code blocks
    </div>
  

        <div id="disqus_thread"></div>
        <script>
            var disqus_config = function () {
              this.page.url = `${window.location.origin}${window.location.pathname}`;
              this.page.identifier = `WebGPU from WebGL`;
            };
            */
            (function() { // DON'T EDIT BELOW THIS LINE
                if (window.location.hostname.indexOf("webgpufundamentals.org") < 0) {
                    return;
                }
                var d = document, s = d.createElement('script');
                s.src = 'https://webgpufundamentals-org.disqus.com/embed.js';
                s.setAttribute('data-timestamp', +new Date());
                (d.head || d.body).appendChild(s);
            })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
        <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </div>
  </div>
</div>
</body>
<script src="/3rdparty/jquery-3.3.1.slim.min.js"></script>
<script src="/webgpu/lessons/resources/prettify.js"></script>
<script src="/webgpu/lessons/resources/lesson.js"></script>
<script>
(function() {
  if (window.location.hostname.indexOf("webgpufundamentals.org") < 0) {
      return;
  }

  function addScript(src, fn) {
    const script = document.createElement('script');
    const firstScript = document.getElementsByTagName('script')[0];
    script.async = true;
    script.defer = true;
    if (fn) {
      script.addEventListener('load', fn);
    }
    script.src = src;
    firstScript.parentNode.insertBefore(script, firstScript);
  }
  /*
  addScript('https://www.googletagmanager.com/gtag/js?id=UA-120733518-1', () => {
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-120733518-1');
  });
  */
}());
</script>


</html>



